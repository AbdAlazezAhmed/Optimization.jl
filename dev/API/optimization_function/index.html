<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>OptimizationFunction · Optimization.jl</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-90474609-3"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-90474609-3', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://Optimization.sciml.ai/stable/API/optimization_function/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="Optimization.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Optimization.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Optimization.jl: A Unified Optimization Package</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/intro/">Basic usage</a></li><li><a class="tocitem" href="../../tutorials/rosenbrock/">Solving the Rosenbrock Problem in &gt;10 Ways</a></li><li><a class="tocitem" href="../../tutorials/minibatch/">Data Iterators and Minibatching</a></li><li><a class="tocitem" href="../../tutorials/symbolic/">Symbolic Problem Building with ModelingToolkit</a></li><li><a class="tocitem" href="../../tutorials/constraints/">Using Equality and Inequality Constraints</a></li></ul></li><li><span class="tocitem">API</span><ul><li><a class="tocitem" href="../optimization_problem/">Defining OptimizationProblems</a></li><li class="is-active"><a class="tocitem" href>OptimizationFunction</a><ul class="internal"><li><a class="tocitem" href="#Automatic-Differentiation-Construction-Choice-Recommendations"><span>Automatic Differentiation Construction Choice Recommendations</span></a></li><li><a class="tocitem" href="#Automatic-Differentiation-Choice-API"><span>Automatic Differentiation Choice API</span></a></li></ul></li><li><a class="tocitem" href="../solve/">Common Solver Options (Solve Keyword Arguments)</a></li><li><a class="tocitem" href="../modelingtoolkit/">ModelingToolkit Integration</a></li></ul></li><li><span class="tocitem">Optimizer Packages</span><ul><li><a class="tocitem" href="../../optimization_packages/blackboxoptim/">BlackBoxOptim.jl</a></li><li><a class="tocitem" href="../../optimization_packages/cmaevolutionstrategy/">CMAEvolutionStrategy.jl</a></li><li><a class="tocitem" href="../../optimization_packages/evolutionary/">Evolutionary.jl</a></li><li><a class="tocitem" href="../../optimization_packages/flux/">Flux.jl</a></li><li><a class="tocitem" href="../../optimization_packages/gcmaes/">GCMAES.jl</a></li><li><a class="tocitem" href="../../optimization_packages/mathoptinterface/">MathOptInterface.jl</a></li><li><a class="tocitem" href="../../optimization_packages/multistartoptimization/">MultistartOptimization.jl</a></li><li><a class="tocitem" href="../../optimization_packages/metaheuristics/">Metaheuristics.jl</a></li><li><a class="tocitem" href="../../optimization_packages/nomad/">NOMAD.jl</a></li><li><a class="tocitem" href="../../optimization_packages/nlopt/">NLopt.jl</a></li><li><a class="tocitem" href="../../optimization_packages/nonconvex/">Nonconvex.jl</a></li><li><a class="tocitem" href="../../optimization_packages/optim/">Optim.jl</a></li><li><a class="tocitem" href="../../optimization_packages/optimisers/">Optimisers.jl</a></li><li><a class="tocitem" href="../../optimization_packages/quaddirect/">QuadDIRECT.jl</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API</a></li><li class="is-active"><a href>OptimizationFunction</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>OptimizationFunction</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/Optimization.jl/blob/master/docs/src/API/optimization_function.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="optfunction"><a class="docs-heading-anchor" href="#optfunction">OptimizationFunction</a><a id="optfunction-1"></a><a class="docs-heading-anchor-permalink" href="#optfunction" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="SciMLBase.OptimizationFunction" href="#SciMLBase.OptimizationFunction"><code>SciMLBase.OptimizationFunction</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">OptimizationFunction{iip,AD,F,G,H,HV,C,CJ,CH,HP,CJP,CHP,S,HCV,CJCV,CHCV} &lt;: AbstractOptimizationFunction{iip}</code></pre><p>A representation of an optimization of an objective function <code>f</code>, defined by:</p><p class="math-container">\[\min_{u} f(u,p)\]</p><p>and all of its related functions, such as the gradient of <code>f</code>, its Hessian, and more. For all cases, <code>u</code> is the state and <code>p</code> are the parameters.</p><p><strong>Constructor</strong></p><pre><code class="language-julia hljs">OptimizationFunction{iip}(f, adtype::AbstractADType = NoAD();
                          grad = nothing, hess = nothing, hv = nothing,
                          cons = nothing, cons_j = nothing, cons_h = nothing,
                          hess_prototype = nothing, cons_jac_prototype = __has_jac_prototype(f) ? f.jac_prototype : nothing,
                          cons_hess_prototype = nothing,
                          syms = __has_syms(f) ? f.syms : nothing, hess_colorvec = __has_colorvec(f) ? f.colorvec : nothing,
                          cons_jac_colorvec = __has_colorvec(f) ? f.colorvec : nothing,
                          cons_hess_colorvec = __has_colorvec(f) ? f.colorvec : nothing,
                          sys = __has_sys(f) ? f.sys : nothing)</code></pre><ul><li><code>adtype</code>: see the section &quot;Defining Optimization Functions via AD&quot;</li><li><code>grad(G,u,p)</code> or <code>G=grad(u,p)</code>: the gradient of <code>f</code> with respect to <code>u</code></li><li><code>hess(H,u,p)</code> or <code>H=hess(u,p)</code>: the Hessian of <code>f</code> with respect to <code>u</code></li><li><code>hv(Hv,u,v,p)</code> or <code>Hv=hv(u,v,p)</code>: the Hessian-vector product <span>$(d^2 f / du^2) v$</span>.</li><li><code>cons(res,x,p)</code> or <code>cons(x,p)</code> : the constraints function, should mutate or return a vector   with value of the <code>i</code>th constraint, evaluated at the current values of variables   inside the optimization routine. This takes just the function evaluations   and the equality or inequality assertion is applied by the solver based on the constraint   bounds passed as <code>lcons</code> and <code>ucons</code> to <a href="../optimization_problem/#SciMLBase.OptimizationProblem"><code>OptimizationProblem</code></a>, in case of equality   constraints <code>lcons</code> and <code>ucons</code> should be passed equal values.</li><li><code>cons_j(res,x,p)</code> or <code>res=cons_j(x,p)</code>: the Jacobian of the constraints.</li><li><code>cons_h(res,x,p)</code> or <code>res=cons_h(x,p)</code>: the Hessian of the constraints, provided as  an array of Hessians with <code>res[i]</code> being the Hessian with respect to the <code>i</code>th output on <code>cons</code>.</li><li><code>paramjac(pJ,u,p)</code>: returns the parameter Jacobian <span>$df/dp$</span>.</li><li><code>hess_prototype</code>: a prototype matrix matching the type that matches the Hessian. For example, if the Hessian is tridiagonal, then an appropriately sized <code>Hessian</code> matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a <code>SparseMatrixCSC</code> with a correct sparsity pattern for the Hessian. The default is <code>nothing</code>, which means a dense Hessian.</li><li><code>cons_jac_prototype</code>: a prototype matrix matching the type that matches the constraint Jacobian. The default is <code>nothing</code>, which means a dense constraint Jacobian.</li><li><code>cons_hess_prototype</code>: a prototype matrix matching the type that matches the constraint Hessian. This is defined as an array of matrices, where <code>hess[i]</code> is the Hessian w.r.t. the <code>i</code>th output. For example, if the Hessian is sparse, then <code>hess</code> is a <code>Vector{SparseMatrixCSC}</code>. The default is <code>nothing</code>, which means a dense constraint Hessian.</li><li><code>syms</code>: the symbol names for the elements of the equation. This should match <code>u0</code> in size. For example, if <code>u = [0.0,1.0]</code> and <code>syms = [:x, :y]</code>, this will apply a canonical naming to the values, allowing <code>sol[:x]</code> in the solution and automatically naming values in plots.</li><li><code>hess_colorvec</code>: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the <code>hess_prototype</code>. This specializes the Hessian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to <code>nothing</code>, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.</li><li><code>cons_jac_colorvec</code>: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the <code>cons_jac_prototype</code>.</li><li><code>cons_hess_colorvec</code>: an array of color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the <code>cons_hess_prototype</code>.</li></ul><p><strong>Defining Optimization Functions Via AD</strong></p><p>While using the keyword arguments gives the user control over defining all of the possible functions, the simplest way to handle the generation of an <code>OptimizationFunction</code> is by specifying an AD type. By doing so, this will automatically fill in all of the extra functions. For example,</p><pre><code class="language-julia hljs">OptimizationFunction(f,AutoZygote())</code></pre><p>will use <a href="https://github.com/FluxML/Zygote.jl">Zygote.jl</a> to define all of the necessary functions. Note that if any functions are defined directly, the auto-AD definition does not overwrite the user&#39;s choice.</p><p>Each of the AD-based constructors are documented separately via their own dispatches.</p><p><strong>iip: In-Place vs Out-Of-Place</strong></p><p>For more details on this argument, see the ODEFunction documentation.</p><p><strong>recompile: Controlling Compilation and Specialization</strong></p><p>For more details on this argument, see the ODEFunction documentation.</p><p><strong>Fields</strong></p><p>The fields of the OptimizationFunction type directly match the names of the inputs.</p></div></section></article><h2 id="Automatic-Differentiation-Construction-Choice-Recommendations"><a class="docs-heading-anchor" href="#Automatic-Differentiation-Construction-Choice-Recommendations">Automatic Differentiation Construction Choice Recommendations</a><a id="Automatic-Differentiation-Construction-Choice-Recommendations-1"></a><a class="docs-heading-anchor-permalink" href="#Automatic-Differentiation-Construction-Choice-Recommendations" title="Permalink"></a></h2><p>The choices for the auto-AD fill-ins with quick descriptions are:</p><ul><li><code>AutoForwardDiff()</code>: The fastest choice for small optimizations</li><li><code>AutoReverseDiff(compile=false)</code>: A fast choice for large scalar optimizations</li><li><code>AutoTracker()</code>: Like ReverseDiff but GPU-compatible</li><li><code>AutoZygote()</code>: The fastest choice for non-mutating array-based (BLAS) functions</li><li><code>AutoFiniteDiff()</code>: Finite differencing, not optimal but always applicable</li><li><code>AutoModelingToolkit()</code>: The fastest choice for large scalar optimizations</li></ul><h2 id="Automatic-Differentiation-Choice-API"><a class="docs-heading-anchor" href="#Automatic-Differentiation-Choice-API">Automatic Differentiation Choice API</a><a id="Automatic-Differentiation-Choice-API-1"></a><a class="docs-heading-anchor-permalink" href="#Automatic-Differentiation-Choice-API" title="Permalink"></a></h2><p>The following sections describe the Auto-AD choices in detail.</p><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>AutoForwardDiff</code>. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>AutoFiniteDiff</code>. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>AutoReverseDiff</code>. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>AutoZygote</code>. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>AutoTracker</code>. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>AutoModelingToolkit</code>. Check Documenter&#39;s build log for details.</p></div></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../optimization_problem/">« Defining OptimizationProblems</a><a class="docs-footer-nextpage" href="../solve/">Common Solver Options (Solve Keyword Arguments) »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Saturday 27 August 2022 14:12">Saturday 27 August 2022</span>. Using Julia version 1.8.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
