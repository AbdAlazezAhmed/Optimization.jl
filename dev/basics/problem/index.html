<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>OptimizationProblem · GalacticOptim.jl</title><link rel="canonical" href="https://galacticoptim.sciml.ai/stable/basics/problem/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="GalacticOptim.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">GalacticOptim.jl</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">GalacticOptim.jl: Unified Global Optimization Package</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/intro/">Introduction to GalacticOptim.jl</a></li></ul></li><li><span class="tocitem">Basics</span><ul><li class="is-active"><a class="tocitem" href>OptimizationProblem</a><ul class="internal"><li><a class="tocitem" href="#OptimizationFunction"><span>OptimizationFunction</span></a></li></ul></li><li><a class="tocitem" href="../solve/">Solver Options</a></li></ul></li><li><span class="tocitem">Local Optimizers</span><ul><li><a class="tocitem" href="../../local_optimizers/local_gradient/">Local Gradient-Based Optimization</a></li><li><a class="tocitem" href="../../local_optimizers/local_derivative_free/">Local Derivative-Free Optimization</a></li><li><a class="tocitem" href="../../local_optimizers/local_hessian/">Local Hessian-Based Second Order Optimization</a></li><li><a class="tocitem" href="../../local_optimizers/local_hessian_free/">Local Hessian-Free Second Order Optimization</a></li></ul></li><li><span class="tocitem">Global Optimizers</span><ul><li><a class="tocitem" href="../../global_optimizers/global/">Global Unconstrained Optimizers</a></li><li><a class="tocitem" href="../../global_optimizers/global_constrained/">Global Constrained Optimization</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Basics</a></li><li class="is-active"><a href>OptimizationProblem</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>OptimizationProblem</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/GalacticOptim.jl/blob/master/docs/src/basics/problem.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Defining-OptimizationProblems"><a class="docs-heading-anchor" href="#Defining-OptimizationProblems">Defining OptimizationProblems</a><a id="Defining-OptimizationProblems-1"></a><a class="docs-heading-anchor-permalink" href="#Defining-OptimizationProblems" title="Permalink"></a></h1><p>All optimizations start by defining an <code>OptimizationProblem</code> as follows:</p><pre><code class="language-julia">OptimizationProblem(f, x, p = DiffEqBase.NullParameters(),;
                    lb = nothing,
                    ub = nothing,
                    lcons = nothing,
                    ucons = nothing,
                    kwargs...)</code></pre><p>Formally, the <code>OptimizationProblem</code> finds the minimum of <code>f(x,p)</code> with an initial condition <code>x</code>. The parameters <code>p</code> are optional. <code>lb</code> and <code>ub</code> are arrays matching the size of <code>x</code> which stand for the lower and upper bounds of <code>x</code> respectively.</p><p><code>f</code> is an <code>OptimizationFunction</code>, as defined below. If <code>f</code> is a standard Julia function, it is automatically converted into an <code>OptimizationFunction</code> with <code>NoAD()</code>, i.e. no automatic generation of the derivative functions.</p><p>Any extra keyword arguments are captured to be sent to the optimizers.</p><h2 id="OptimizationFunction"><a class="docs-heading-anchor" href="#OptimizationFunction">OptimizationFunction</a><a id="OptimizationFunction-1"></a><a class="docs-heading-anchor-permalink" href="#OptimizationFunction" title="Permalink"></a></h2><p>The <code>OptimizationFunction</code> type is a function type that holds all of the extra differentiation data required to do fast and accurate optimization. The signature for the constructor is:</p><pre><code class="language-julia">OptimizationFunction{iip}(f,adtype=NoAD();
                          grad=nothing,
                          hess=nothing,
                          hv=nothing,
                          cons=nothing,
                          cons_j=nothing,
                          cons_h=nothing)</code></pre><p>The keyword arguments are as follows:</p><ul><li><code>grad</code>: Gradient</li><li><code>hess</code>: Hessian</li><li><code>hv</code>: Hessian vector products <code>hv(du,u,p,t,v)</code> = H*v</li><li><code>cons</code>: Constraint function</li><li><code>cons_j</code></li><li><code>cons_h</code></li></ul><h3 id="Defining-Optimization-Functions-Via-AD"><a class="docs-heading-anchor" href="#Defining-Optimization-Functions-Via-AD">Defining Optimization Functions Via AD</a><a id="Defining-Optimization-Functions-Via-AD-1"></a><a class="docs-heading-anchor-permalink" href="#Defining-Optimization-Functions-Via-AD" title="Permalink"></a></h3><p>While using the keyword arguments gives the user control over defining all of the possible functions, the simplest way to handle the generation of an <code>OptimizationFunction</code> is by specifying an AD type. By doing so, this will automatically fill in all of the extra functions. For example,</p><pre><code class="language-julia">OptimizationFunction(f,AutoZygote())</code></pre><p>will use <a href="https://github.com/FluxML/Zygote.jl">Zygote.jl</a> to define all of the necessary functions. Note that if any functions are defined directly, the auto-AD definition does not overwrite the user&#39;s choice.</p><p>The choices for the auto-AD fill-ins with quick descriptions are:</p><ul><li><code>AutoForwardDiff()</code>: The fastest choice for small optimizations</li><li><code>AutoReverseDiff(compile=false)</code>: A fast choice for large scalar optimizations</li><li><code>AutoTracker()</code>: Like ReverseDiff but GPU-compatible</li><li><code>AutoZygote()</code>: The fastest choice</li><li><code>AutoFiniteDiff()</code>: Finite differencing, not optimal but always applicable</li><li><code>AutoModelingToolkit()</code>: The fastest choice for large scalar optimizations</li></ul><p>The following sections describe the Auto-AD choices in detail.</p><h3 id="AutoForwardDiff"><a class="docs-heading-anchor" href="#AutoForwardDiff">AutoForwardDiff</a><a id="AutoForwardDiff-1"></a><a class="docs-heading-anchor-permalink" href="#AutoForwardDiff" title="Permalink"></a></h3><p>This uses the <a href="https://github.com/JuliaDiff/ForwardDiff.jl">ForwardDiff.jl</a> package. It is the fastest choice for small systems, especially with heavy scalar interactions. It is easy to use and compatible with most pure is Julia functions which have loose type restrictions. However, because it&#39;s forward-mode, it scales poorly in comparison to other AD choices. Hessian construction is suboptimal as it uses the forward-over-forward approach.</p><ul><li>Compatible with GPUs</li><li>Compatible with Hessian-based optimization</li><li>Compatible with Hv-based optimization</li><li>Compatible with constraints</li></ul><h3 id="AutoReverseDiff"><a class="docs-heading-anchor" href="#AutoReverseDiff">AutoReverseDiff</a><a id="AutoReverseDiff-1"></a><a class="docs-heading-anchor-permalink" href="#AutoReverseDiff" title="Permalink"></a></h3><p>This uses the <a href="https://github.com/JuliaDiff/ReverseDiff.jl">ReverseDiff.jl</a> package. <code>AutoReverseDiff</code> has a default argument, <code>compile</code>, which denotes whether the reverse pass should be compiled. <strong><code>compile</code> should only be set to <code>true</code> if <code>f</code> contains no branches (if statements, while loops) otherwise it can produce incorrect derivatives!</strong>.</p><p><code>AutoReverseDiff</code> is generally applicable to many pure Julia codes, and with <code>compile=true</code> it is one of the fastest options on code with heavy scalar interactions. Hessian calculations are fast by mixing ForwardDiff with ReverseDiff for forward-over-reverse. However, its performance can falter when <code>compile=false</code>.</p><ul><li>Not compatible with GPUs</li><li>Compatible with Hessian-based optimization by mixing with ForwardDiff</li><li>Compatible with Hv-based optimization by mixing with ForwardDiff</li><li>Not compatible with constraint functions</li></ul><h3 id="AutoTracker"><a class="docs-heading-anchor" href="#AutoTracker">AutoTracker</a><a id="AutoTracker-1"></a><a class="docs-heading-anchor-permalink" href="#AutoTracker" title="Permalink"></a></h3><p>This uses the <a href="https://github.com/FluxML/Tracker.jl">Tracker.jl</a> package. Generally slower than ReverseDiff, it is generally applicable to many pure Julia codes.</p><ul><li>Compatible with GPUs</li><li>Not compatible with Hessian-based optimization</li><li>Not compatible with Hv-based optimization</li><li>Not compatible with constraint functions</li></ul><h3 id="AutoZygote"><a class="docs-heading-anchor" href="#AutoZygote">AutoZygote</a><a id="AutoZygote-1"></a><a class="docs-heading-anchor-permalink" href="#AutoZygote" title="Permalink"></a></h3><p>This uses the <a href="https://github.com/FluxML/Zygote.jl">Zygote.jl</a> package. This is the staple reverse-mode AD that handles a large portion of Julia with good efficiency. Hessian construction is fast via forward-over-reverse mixing ForwardDiff.jl with Zygote.jl</p><ul><li>Compatible with GPUs</li><li>Compatible with Hessian-based optimization via ForwardDiff</li><li>Compatible with Hv-based optimization via ForwardDiff</li><li>Not compatible with constraint functions</li></ul><h3 id="AutoFiniteDiff"><a class="docs-heading-anchor" href="#AutoFiniteDiff">AutoFiniteDiff</a><a id="AutoFiniteDiff-1"></a><a class="docs-heading-anchor-permalink" href="#AutoFiniteDiff" title="Permalink"></a></h3><p>This uses <a href="https://github.com/JuliaDiff/FiniteDiff.jl">FiniteDiff.jl</a>. While to necessarily the most efficient in any case, this is the only choice that doesn&#39;t require the <code>f</code> function to be automatically differentiable, which means it applies to any choice. However, because it&#39;s using finite differencing, one needs to be careful as this procedure introduces numerical error into the derivative estimates.</p><ul><li>Compatible with GPUs</li><li>Compatible with Hessian-based optimization</li><li>Compatible with Hv-based optimization</li><li>Not compatible with constraint functions</li></ul><h3 id="AutoModelingToolkit"><a class="docs-heading-anchor" href="#AutoModelingToolkit">AutoModelingToolkit</a><a id="AutoModelingToolkit-1"></a><a class="docs-heading-anchor-permalink" href="#AutoModelingToolkit" title="Permalink"></a></h3><p>This uses the <a href="https://github.com/SciML/ModelingToolkit.jl">ModelingToolkit.jl</a> symbolic system for automatically converting the <code>f</code> function into a symbolic equation and uses symbolic differentiation in order to generate a fast derivative code. Note that this will also compile a new version of your <code>f</code> function that is automatically optimized. In this choice, it defaults to <code>grad=false</code> and <code>hess=false</code>, and one must change these to <code>true</code> in order to enable the symbolic derivation. Future updates will enable automatic parallelization and sparsity in the derived functions. This can be the fastest for many systems, especially when parallelization and sparsity are required, but can take the longest to generate.</p><ul><li>Not compatible with GPUs</li><li>Compatible with Hessian-based optimization</li><li>Not compatible with Hv-based optimization</li><li>Not compatible with constraint functions</li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../tutorials/intro/">« Introduction to GalacticOptim.jl</a><a class="docs-footer-nextpage" href="../solve/">Solver Options »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 28 January 2021 18:28">Thursday 28 January 2021</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
