var documenterSearchIndex = {"docs":
[{"location":"usage/#Usage","page":"Usage","title":"Usage","text":"","category":"section"},{"location":"usage/#Automatic-Differentiation-Choices","page":"Usage","title":"Automatic Differentiation Choices","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"While one can fully define all of the derivative functions associated with nonlinear constrained optimization directly, in many cases it's easiest to just rely on automatic differentiation to derive those functions. In GalacticOptim.jl, you can provide as few functions as you want, or give a differentiation library choice.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"AutoForwardDiff()\nAutoReverseDiff(compile=false)\nAutoTracker()\nAutoZygote()\nAutoFiniteDiff()\nAutoModelingToolkit()","category":"page"},{"location":"usage/#API-Documentation","page":"Usage","title":"API Documentation","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"OptimizationFunction(f, AutoForwardDiff();\n                     grad = nothing,\n                     hes = nothing,\n                     hv = nothing,\n                     chunksize = 1)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"OptimizationProblem(f, x, p = DiffEqBase.NullParameters(),;\n                    lb = nothing,\n                    ub = nothing)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"solve(prob,alg;kwargs...)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Keyword arguments:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"maxiters (the maximum number of iterations)\nabstol (absolute tolerance)\nreltol (relative tolerance)","category":"page"},{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":" using GalacticOptim, Optim\n rosenbrock(x,p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\n x0 = zeros(2)\n p  = [1.0,100.0]\n\n prob = OptimizationProblem(rosenbrock,x0,p)\n sol = solve(prob,NelderMead())\n\n\n using BlackBoxOptim\n prob = OptimizationProblem(rosenbrock, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\n sol = solve(prob,BBO())","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Note that Optim.jl is a core dependency of GalaticOptim.jl. However, BlackBoxOptim.jl is not and must already be installed (see the list above).","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Warning: The output of the second optimization task (BBO()) is currently misleading in the sense that it returns Status: failure (reached maximum number of iterations). However, convergence is actually reached and the confusing message stems from the reliance on the Optim.jl output  struct (where the situation of reaching the maximum number of iterations is rightly regarded as a failure). The improved output struct will soon be implemented.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"The output of the first optimization task (with the NelderMead() algorithm) is given below:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"* Status: success\n\n* Candidate solution\n   Final objective value:     3.525527e-09\n\n* Found with\n   Algorithm:     Nelder-Mead\n\n* Convergence measures\n   √(Σ(yᵢ-ȳ)²)/n ≤ 1.0e-08\n\n* Work counters\n   Seconds run:   0  (vs limit Inf)\n   Iterations:    60\n   f(x) calls:    118","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"We can also explore other methods in a similar way:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":" f = OptimizationFunction(rosenbrock, GalacticOptim.AutoForwardDiff())\n prob = OptimizationProblem(f, x0, p)\n sol = solve(prob,BFGS())","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"For instance, the above optimization task produces the following output:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"* Status: success\n\n* Candidate solution\n   Final objective value:     7.645684e-21\n\n* Found with\n   Algorithm:     BFGS\n\n* Convergence measures\n   |x - x'|               = 3.48e-07 ≰ 0.0e+00\n   |x - x'|/|x'|          = 3.48e-07 ≰ 0.0e+00\n   |f(x) - f(x')|         = 6.91e-14 ≰ 0.0e+00\n   |f(x) - f(x')|/|f(x')| = 9.03e+06 ≰ 0.0e+00\n   |g(x)|                 = 2.32e-09 ≤ 1.0e-08\n\n* Work counters\n   Seconds run:   0  (vs limit Inf)\n   Iterations:    16\n   f(x) calls:    53\n   ∇f(x) calls:   53","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":" prob = OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\n sol = solve(prob, Fminbox(GradientDescent()))","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"The examples clearly demonstrate that GalacticOptim.jl provides an intuitive way of specifying optimization tasks and offers a relatively easy access to a wide range of optimization algorithms.","category":"page"},{"location":"#GalacticOptim.jl","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl","text":"","category":"section"},{"location":"","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl: Unified Global Optimization Package","text":"GalacticOptim.jl is a package with a scope that is beyond your normal global optimization package. GalacticOptim.jl seeks to bring together all of the optimization packages it can find, local and global, into one unified Julia interface. This means, you learn one package and you learn them all! GalacticOptim.jl adds a few high-level features, such as integrating with automatic differentiation, to make its usage fairly simple for most cases, while allowing all of the options in a single unified interface.","category":"page"},{"location":"#Note:-This-package-is-still-in-development.-This-guide-is-currently-both-an-active-documentation-and-a-development-roadmap.","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"Note: This package is still in development. This guide is currently both an active documentation and a development roadmap.","text":"","category":"section"},{"location":"#Installation","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"Installation","text":"","category":"section"},{"location":"","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl: Unified Global Optimization Package","text":"Assuming that you already have Julia correctly installed, it suffices to import GalacticOptim.jl in the standard way:","category":"page"},{"location":"","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl: Unified Global Optimization Package","text":"import Pkg; Pkg.add(\"GalacticOptim\")","category":"page"},{"location":"","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl: Unified Global Optimization Package","text":"The packages relevant to the core functionality of GalacticOptim.jl will be imported accordingly and, in most cases, you do not have to worry about the manual installation of dependencies. Below is the list of packages that need to be installed explicitly if you intend to use the specific optimization algorithms offered by them:","category":"page"},{"location":"","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl: Unified Global Optimization Package","text":"BlackBoxOptim.jl (solver: BBO())\nNLopt.jl (usage via the NLopt API;","category":"page"},{"location":"","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl: Unified Global Optimization Package","text":"see also the available algorithms)","category":"page"},{"location":"","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl: Unified Global Optimization Package","text":"MultistartOptimization.jl","category":"page"},{"location":"","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl: Unified Global Optimization Package","text":"(see also this documentation)","category":"page"},{"location":"","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl: Unified Global Optimization Package","text":"QuadDIRECT.jl\nEvolutionary.jl (see also this documentation)\nCMAEvolutionStrategy.jl","category":"page"},{"location":"optimizers/#Available-optimizers-by-categories","page":"Available optimizers","title":"Available optimizers by categories","text":"","category":"section"},{"location":"optimizers/","page":"Available optimizers","title":"Available optimizers","text":"The first entries give the original name and package of the optimizers (and are linked to their source documentation). The comments in the next line describe the usage of the optimizers in GalacticOptim.jl and list the default values of the constructors.","category":"page"},{"location":"optimizers/","page":"Available optimizers","title":"Available optimizers","text":"Note that the default value of the maximum number of iterations is 1000. It can be changed by doing: solve(problem, optimizer, maxiters = 2000).","category":"page"},{"location":"optimizers/#Global-optimizers","page":"Available optimizers","title":"Global optimizers","text":"","category":"section"},{"location":"optimizers/","page":"Available optimizers","title":"Available optimizers","text":"Optim.ParticleSwarm: Particle Swarm Optimization\nsolve(problem, ParticleSwarm(lower, upper, n_particles))\nlower/upper are vectors of lower/upper bounds respectively\nn_particles is the number of particles in the swarm\ndefaults to: lower = [], upper = [], n_particles = 0\nBlackBoxOptim: (Meta-)heuristic/stochastic algorithms\nsolve(problem, BBO(method))\nthe name of the method must be preceded by :, for example: :de_rand_2_bin\nin GalacticOptim.jl, BBO() defaults to the recommended adaptive_de_rand_1_bin_radiuslimited\nthe available methods are listed here\nQuadDIRECT: QuadDIRECT algorithm (inspired by DIRECT and MCS)\nsolve(problem, QuadDirect(), splits)\nsplits is a list of 3-vectors with initial locations at which to evaluate the function (the values must be in strictly increasing order and lie within the specified bounds), for instance:\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb=[-3, -2], ub=[3, 2])   solve(prob, QuadDirect(), splits = ([-2, 0, 2], [-1, 0, 1]))\nalso note that QuadDIRECT should (for now) be installed by doing: ] add https://github.com/timholy/QuadDIRECT.jl.git\nEvolutionary.GA: Genetic Algorithm optimizer\nEvolutionary.ES: Evolution Strategy algorithm\nEvolutionary.CMAES: Covariance Matrix Adaptation Evolution Strategy algorithm\nCMAEvolutionStrategy: Covariance Matrix Adaptation Evolution Strategy algorithm","category":"page"},{"location":"optimizers/#Local-gradient-based-optimizers","page":"Available optimizers","title":"Local gradient-based optimizers","text":"","category":"section"},{"location":"optimizers/","page":"Available optimizers","title":"Available optimizers","text":"Flux.Optimise.Descent: Classic gradient descent optimizer with learning rate\nsolve(problem, Descent(η))\nη is the learning rate\ndefaults to: η = 0.1\nFlux.Optimise.Momentum: Classic gradient descent optimizer with learning rate and momentum\nsolve(problem, Momentum(η, ρ))\nη is the learning rate\nρ is the momentum\ndefaults to: η = 0.01, ρ = 0.9\nFlux.Optimise.Nesterov: Gradient descent optimizer with learning rate and Nesterov momentum\nsolve(problem, Nesterov(η, ρ))\nη is the learning rate\nρ is the Nesterov momentum\ndefaults to: η = 0.01, ρ = 0.9\nFlux.Optimise.RMSProp: RMSProp optimizer\nsolve(problem, RMSProp(η, ρ))\nη is the learning rate\nρ is the momentum\ndefaults to: η = 0.001, ρ = 0.9\nFlux.Optimise.ADAM: ADAM optimizer\nsolve(problem, ADAM(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\ndefaults to: η = 0.001, β::Tuple = (0.9, 0.999)\nFlux.Optimise.RADAM: Rectified ADAM optimizer\nsolve(problem, RADAM(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\ndefaults to: η = 0.001, β::Tuple = (0.9, 0.999)\nFlux.Optimise.AdaMax: AdaMax optimizer\nsolve(problem, AdaMax(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\ndefaults to: η = 0.001, β::Tuple = (0.9, 0.999)\nFlux.Optimise.ADAGRad: ADAGrad optimizer\nsolve(problem, ADAGrad(η))\nη is the learning rate\ndefaults to: η = 0.1\nFlux.Optimise.ADADelta: ADADelta optimizer\nsolve(problem, ADADelta(ρ))\nρ is the gradient decay factor\ndefaults to: ρ = 0.9\nFlux.Optimise.AMSGrad: AMSGrad optimizer\nsolve(problem, AMSGrad(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\ndefaults to: η = 0.001, β::Tuple = (0.9, 0.999)\nFlux.Optimise.NADAM: Nesterov variant of the ADAM optimizer\nsolve(problem, NADAM(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\ndefaults to: η = 0.001, β::Tuple = (0.9, 0.999)\nFlux.Optimise.ADAMW: ADAMW optimizer\nsolve(problem, ADAMW(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\ndecay is the decay to weights\ndefaults to: η = 0.001, β::Tuple = (0.9, 0.999), decay = 0\nOptim.ConjugateGradient: Conjugate Gradient Descent\nsolve(problem, ConjugateGradient(alphaguess, linesearch, eta, P, precondprep))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\neta determines the next step direction\nP is an optional preconditioner (for more information, see this source)\nprecondpred is used to update P as the state variable x changes\ndefaults to:\nalphaguess = LineSearches.InitialHagerZhang(),   linesearch = LineSearches.HagerZhang(),   eta = 0.4,   P = nothing,   precondprep = (P, x) -> nothing\nOptim.GradientDescent: Gradient Descent (a quasi-Newton solver)\nsolve(problem, GradientDescent(alphaguess, linesearch, P, precondprep))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nP is an optional preconditioner (for more information, see this source)\nprecondpred is used to update P as the state variable x changes\ndefaults to:\nalphaguess = LineSearches.InitialPrevious(),   linesearch = LineSearches.HagerZhang(),   P = nothing,   precondprep = (P, x) -> nothing\nOptim.BFGS: Broyden-Fletcher-Goldfarb-Shanno algorithm\nsolve(problem, BFGS(alpaguess, linesearch, initial_invH, initial_stepnorm, manifold))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\ninitial_invH specifies an optional initial matrix\ninitial_stepnorm determines that initial_invH is an identity matrix scaled by the value of initial_stepnorm multiplied by the sup-norm of the gradient at the initial point\nmanifold specifies a (Riemannian) manifold on which the function is to be minimized (for more information, consult this source)\navailable manifolds:\nFlat\nSphere\nStiefel\nmeta-manifolds:\nPowerManifold\nProductManifold\ncustom manifolds\ndefaults to: alphaguess = LineSearches.InitialStatic(), linesearch = LineSearches.HagerZhang(), initial_invH = nothing, initial_stepnorm = nothing, manifold = Flat()\nOptim.LBFGS: Limited-memory Broyden-Fletcher-Goldfarb-Shanno algorithm","category":"page"},{"location":"optimizers/#Local-derivative-free-optimizers","page":"Available optimizers","title":"Local derivative-free optimizers","text":"","category":"section"},{"location":"optimizers/","page":"Available optimizers","title":"Available optimizers","text":"Optim.NelderMead: Nelder-Mead optimizer\nsolve(problem, NelderMead(parameters, initial_simplex))\nparameters = AdaptiveParameters() or parameters = FixedParameters()\ninitial_simplex = AffineSimplexer()\ndefaults to: parameters = AdaptiveParameters(), initial_simplex = AffineSimplexer()\nOptim.SimulatedAnnealing: Simulated Annealing\nsolve(problem, SimulatedAnnealing(neighbor, T, p))\nneighbor is a mutating function of the current and proposed x\nT is a function of the current iteration that returns a temperature\np is a function of the current temperature\ndefaults to: neighbor = default_neighbor!, T = default_temperature, p = kirkpatrick","category":"page"},{"location":"optimizers/#Second-order-optimizers","page":"Available optimizers","title":"Second-order optimizers","text":"","category":"section"},{"location":"optimizers/","page":"Available optimizers","title":"Available optimizers","text":"Optim.Newton","category":"page"},{"location":"optimizers/#Constrained-local-optimization","page":"Available optimizers","title":"Constrained local optimization","text":"","category":"section"},{"location":"optimizers/","page":"Available optimizers","title":"Available optimizers","text":"Optim.IPNewton","category":"page"},{"location":"optimizers/#Constrained-global-optimization","page":"Available optimizers","title":"Constrained global optimization","text":"","category":"section"},{"location":"optimizers/","page":"Available optimizers","title":"Available optimizers","text":"Optim.SAMIN: Simulated Annealing with bounds\nsolve(problem, SAMIN(nt, ns, rt, neps, f_tol, x_tol, coverage_ok, verbosity))\ndefaults to:\n```   SAMIN(; nt::Int = 5  # reduce temperature every ntnsdim(xinit) evaluations           ns::Int = 5  # adjust bounds every ns*dim(xinit) evaluations           rt::T = 0.9  # geometric temperature reduction factor: when temp changes, new temp is t=rt*t           neps::Int = 5  # number of previous best values the final result is compared to           ftol::T = 1e-12  # the required tolerance level for function value comparisons           xtol::T = 1e-6  # the required tolerance level for x           coverage_ok::Bool = false,  # if false, increase temperature until initial parameter space is covered           verbosity::Int = 0)  # scalar: 0, 1, 2 or 3 (default = 0).\ncopied verbatim from https://julianlsolvers.github.io/Optim.jl/stable/#algo/samin/#constructor\n```","category":"page"}]
}
