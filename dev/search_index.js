var documenterSearchIndex = {"docs":
[{"location":"optimization_packages/blackboxoptim/#BlackBoxOptim.jl","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"","category":"section"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"BlackBoxOptim is a is a Julia package implementing (Meta-)heuristic/stochastic algorithms that do not require for the optimized function to be differentiable.","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"A BlackBoxOptim algorithm is called by BBO_ prefix followed by the algorithm name:","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Natural Evolution Strategies:\nSeparable NES: BBO_separable_nes()\nExponential NES: BBO_xnes()\nDistance-weighted Exponential NES: BBO_dxnes()\nDifferential Evolution optimizers, 5 different:\nAdaptive DE/rand/1/bin: BBO_adaptive_de_rand_1_bin()\nAdaptive DE/rand/1/bin with radius limited sampling: BBO_adaptive_de_rand_1_bin_radiuslimited()\nDE/rand/1/bin: BBO_de_rand_1_bin()\nDE/rand/1/bin with radius limited sampling (a type of trivial geography): BBO_de_rand_1_bin_radiuslimited()\nDE/rand/2/bin: de_rand_2_bin()\nDE/rand/2/bin with radius limited sampling (a type of trivial geography): BBO_de_rand_2_bin_radiuslimited()\nDirect search:\nGenerating set search:\nCompass/coordinate search: BBO_generating_set_search()\nDirect search through probabilistic descent: BBO_probabilistic_descent()\nResampling Memetic Searchers:\nResampling Memetic Search (RS): BBO_resampling_memetic_search()\nResampling Inheritance Memetic Search (RIS): BBO_resampling_inheritance_memetic_search()\nStochastic Approximation:\nSimultaneous Perturbation Stochastic Approximation (SPSA): BBO_simultaneous_perturbation_stochastic_approximation()\nRandomSearch (to compare to): BBO_random_search()","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The recommended optimizer is BBO_adaptive_de_rand_1_bin_radiuslimited()","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The currently available algorithms are listed here","category":"page"},{"location":"optimization_packages/blackboxoptim/#Global-Optimizer","page":"BlackBoxOptim.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/blackboxoptim/#Without-Constraint-Equations","page":"BlackBoxOptim.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The algorithms in BlackBoxOptim are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The Rosenbrock function can optimized using the BBO_adaptive_de_rand_1_bin_radiuslimited() as follows:","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, BBO_adaptive_de_rand_1_bin_radiuslimited(), maxiters=100000, maxtime=1000.0)","category":"page"},{"location":"optimization_packages/nlopt/#NLopt.jl","page":"NLopt.jl","title":"NLopt.jl","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt is Julia package interfacing to the free/open-source NLopt library which implements many optimization methods both global and local NLopt Documentation.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.jl algorithms are chosen either via NLopt.Opt(:algname, nstates) where nstates is the number of states to be optimized but preferably via NLopt.AlgorithmName() where `AlgorithmName can be one of the following:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.GN_DIRECT()\nNLopt.GN_DIRECT_L()\nNLopt.GN_DIRECT_L_RAND()\nNLopt.GN_DIRECT_NOSCAL()\nNLopt.GN_DIRECT_L_NOSCAL()\nNLopt.GN_DIRECT_L_RAND_NOSCAL()\nNLopt.GN_ORIG_DIRECT()\nNLopt.GN_ORIG_DIRECT_L()\nNLopt.GD_STOGO()\nNLopt.GD_STOGO_RAND()\nNLopt.LD_LBFGS_NOCEDAL()\nNLopt.LD_LBFGS()\nNLopt.LN_PRAXIS()\nNLopt.LD_VAR1()\nNLopt.LD_VAR2()\nNLopt.LD_TNEWTON()\nNLopt.LD_TNEWTON_RESTART()\nNLopt.LD_TNEWTON_PRECOND()\nNLopt.LD_TNEWTON_PRECOND_RESTART()\nNLopt.GN_CRS2_LM()\nNLopt.GN_MLSL()\nNLopt.GD_MLSL()\nNLopt.GN_MLSL_LDS()\nNLopt.GD_MLSL_LDS()\nNLopt.LD_MMA()\nNLopt.LN_COBYLA()\nNLopt.LN_NEWUOA()\nNLopt.LN_NEWUOA_BOUND()\nNLopt.LN_NELDERMEAD()\nNLopt.LN_SBPLX()\nNLopt.LN_AUGLAG()\nNLopt.LD_AUGLAG()\nNLopt.LN_AUGLAG_EQ()\nNLopt.LD_AUGLAG_EQ()\nNLopt.LN_BOBYQA()\nNLopt.GN_ISRES()\nNLopt.AUGLAG()\nNLopt.AUGLAG_EQ()\nNLopt.G_MLSL()\nNLopt.G_MLSL_LDS()\nNLopt.LD_SLSQP()\nNLopt.LD_CCSAQ()\nNLopt.GN_ESCH()\nNLopt.GN_AGS()","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"See the NLopt Documentation for more details on each optimizer.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"Beyond the common arguments the following optimizer parameters can be set as kwargs:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"stopval\nxtol_rel\nxtol_abs\nconstrtol_abs\ninitial_step\npopulation\nvector_storage","category":"page"},{"location":"optimization_packages/nlopt/#Local-Optimizer","page":"NLopt.jl","title":"Local Optimizer","text":"","category":"section"},{"location":"optimization_packages/nlopt/#Derivative-Free","page":"NLopt.jl","title":"Derivative-Free","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"Derivative-free optimizers are optimizers that can be used even in cases where no derivatives or automatic differentiation is specified. While they tend to be less efficient than derivative-based optimizers, they can be easily applied to cases where defining derivatives is difficult. Note that while these methods do not support general constraints, all support bounds constraints via lb and ub in the OptimizationProblem.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt derivative-free optimizers are:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.LN_PRAXIS()\nNLopt.LN_COBYLA()\nNLopt.LN_NEWUOA()\nNLopt.LN_NEWUOA_BOUND()\nNLopt.LN_NELDERMEAD()\nNLopt.LN_SBPLX()\nNLopt.LN_AUGLAG()\nNLopt.LN_AUGLAG_EQ()\nNLopt.LN_BOBYQA()","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The Rosenbrock function can optimized using the NLopt.LN_NELDERMEAD() as follows:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, NLopt.LN_NELDERMEAD())","category":"page"},{"location":"optimization_packages/nlopt/#Gradient-Based","page":"NLopt.jl","title":"Gradient-Based","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"Gradient-based optimizers are optimizers which utilise the gradient information based on derivatives defined or automatic differentiation.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt gradient-based optimizers are:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.LD_LBFGS_NOCEDAL()\nNLopt.LD_LBFGS()\nNLopt.LD_VAR1()\nNLopt.LD_VAR2()\nNLopt.LD_TNEWTON()\nNLopt.LD_TNEWTON_RESTART()\nNLopt.LD_TNEWTON_PRECOND()\nNLopt.LD_TNEWTON_PRECOND_RESTART()\nNLopt.LD_MMA()\nNLopt.LD_AUGLAG()\nNLopt.LD_AUGLAG_EQ()\nNLopt.LD_SLSQP()\nNLopt.LD_CCSAQ()","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The Rosenbrock function can optimized using NLopt.LD_LBFGS() as follows:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, GalacticOptim.AutoForwardDiff())\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, NLopt.LD_LBFGS())","category":"page"},{"location":"optimization_packages/nlopt/#Global-Optimizer","page":"NLopt.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/nlopt/#Without-Constraint-Equations","page":"NLopt.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The following algorithms in NLopt are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt global optimizers which fall into this category are:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.GN_DIRECT()\nNLopt.GN_DIRECT_L()\nNLopt.GN_DIRECT_L_RAND()\nNLopt.GN_DIRECT_NOSCAL()\nNLopt.GN_DIRECT_L_NOSCAL()\nNLopt.GN_DIRECT_L_RAND_NOSCAL()\nNLopt.GD_STOGO()\nNLopt.GD_STOGO_RAND()\nNLopt.GN_CRS2_LM()\nNLopt.GN_MLSL()\nNLopt.GD_MLSL()\nNLopt.GN_MLSL_LDS()\nNLopt.GD_MLSL_LDS()\nNLopt.G_MLSL()\nNLopt.G_MLSL_LDS()\nNLopt.GN_ESCH()","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The Rosenbrock function can optimized using NLopt.GN_DIRECT() as follows:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, NLopt.GN_DIRECT())","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"Algorithms such as NLopt.G_MLSL() or NLopt.G_MLSL_LDS() also require a local optimiser to be selected which via the local_method argument of solve.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The Rosenbrock function can optimized using NLopt.G_MLSL_LDS() with NLopt.LN_NELDERMEAD() as the local optimizer. The local optimizer maximum iterations are set via local_maxiters:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, GalacticOptim.AutoForwardDiff())\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, NLopt.G_MLSL_LDS(), local_method = NLopt.LD_LBFGS(), local_maxiters=10000)","category":"page"},{"location":"optimization_packages/nlopt/#With-Constraint-Equations","page":"NLopt.jl","title":"With Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The following algorithms in NLopt are performing global optimization on problems with constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"note: Constraints with NLopt\nEquality and inequality equation support for NLopt via GalacticOptim is not supported directly. However, you can use the MOI wrapper to use constraints with NLopt optimisers.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt global optimizers which fall into this category are:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.GN_ORIG_DIRECT()\nNLopt.GN_ORIG_DIRECT_L()\nNLopt.GN_ISRES()\nNLopt.GN_AGS()","category":"page"},{"location":"API/solve/#Common-Solver-Options","page":"solve","title":"Common Solver Options","text":"","category":"section"},{"location":"API/solve/","page":"solve","title":"solve","text":"In GalacticOptim.jl, solving an OptimizationProblem is done via:","category":"page"},{"location":"API/solve/","page":"solve","title":"solve","text":"solve(prob,alg;kwargs...)","category":"page"},{"location":"API/solve/","page":"solve","title":"solve","text":"The arguments to solve are common across all of the optimizers. These common arguments are:","category":"page"},{"location":"API/solve/","page":"solve","title":"solve","text":"maxiters (the maximum number of iterations)\nmaxtime (the maximum of time the optimization runs for)\nabstol (absolute tolerance in changes of the objective value)\nreltol (relative tolerance  in changes of the objective value)\ncb (a callback function)","category":"page"},{"location":"API/solve/","page":"solve","title":"solve","text":"If the chosen global optimzer employs a local optimization method a similiar set of common local optimizer arguments exists. The common local optimizer arguments are:","category":"page"},{"location":"API/solve/","page":"solve","title":"solve","text":"local_method (optimiser used for local optimization in global method)\nlocal_maxiters (the maximum number of iterations)\nlocal_maxtime (the maximum of time the optimization runs for)\nlocal_abstol (absolute tolerance in changes of the objective value)\nlocal_reltol (relative tolerance  in changes of the objective value)\nlocal_options (NamedTuple of keyword arguments for local optimizer)","category":"page"},{"location":"API/solve/","page":"solve","title":"solve","text":"Some optimizer algorithms have special keyword arguments documented in the solver portion of the documentation and their respective documentation. These arguments can be passed as kwargs... to solve. Similiarly, the special kewyword arguments for the local_method of a global optimizer are passed as a NamedTuple to local_options.","category":"page"},{"location":"API/solve/","page":"solve","title":"solve","text":"Over time we hope to cover more of these keyword arguments under the common interface.","category":"page"},{"location":"API/solve/","page":"solve","title":"solve","text":"If a common argument is not implemented for a optimizer a warning will be shown.  ","category":"page"},{"location":"API/solve/#Callback-Functions","page":"solve","title":"Callback Functions","text":"","category":"section"},{"location":"API/solve/","page":"solve","title":"solve","text":"The callback function cb is a function which is called after every optimizer step. Its signature is:","category":"page"},{"location":"API/solve/","page":"solve","title":"solve","text":"cb = (x,other_args) -> false","category":"page"},{"location":"API/solve/","page":"solve","title":"solve","text":"where other_args is are the extra return arguments of the optimization f. For example, if f(x,p) = 5x, then cb = (x) -> ... is used. If f(x,p) = 5x,55x, then cb = (x,extra) -> ... is used, where extra = 55x. This allows for saving values from the optimization and using them for plotting and display without recalculating. The callback should return a Boolean value, and the default  should be false, such that the optimization gets stopped if it returns true.","category":"page"},{"location":"optimization_packages/metaheuristics/#Metaheuristics.jl","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Metaheuristics is a is a Julia package implementing metaheuristic algorithms for global optiimization that do not require for the optimized function to be differentiable.","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"A Metaheuristics Single-Objective algorithm is called using one of the following:","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Evolutionary Centers Algorithm: ECA()\nDifferential Evolution: DE() with 5 different stratgies\nDE(strategy=:rand1) - default strategy\nDE(strategy=:rand2)\nDE(strategy=:best1)\nDE(strategy=:best2)\nDE(strategy=:randToBest1)\nParticle Swarm Optimization: PSO()\nArtificial Bee Colony: ABC()\nGravitational Search Algorithm: CGSA()\nSimulated Annealing: SA()\nWhale Optimization Algorithm: WOA()","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Metaheuristics also performs Multiobjective optimization but this is not yet supported by GalacticOptim.","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Each optimizer sets default settings based on the optimization problem but specific parameters can be set as shown in the original Documentation ","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Additionally, Metaheuristics common settings which would be defined by Metaheuristics.Options can be simply passed as special keywoard arguments to solve without the need to use the Metaheuristics.Options struct.","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Lastly, information about the optimization problem such as the true optimum is set via Metaheuristics.Information and passed as part of the optimizer struct to solve e.g. solve(prob, ECA(information=Metaheuristics.Inoformation(f_optimum = 0.0)))","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"The currently available algorithms and their parameters are listed here.","category":"page"},{"location":"optimization_packages/metaheuristics/#Global-Optimizer","page":"Metaheuristics.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/#Without-Constraint-Equations","page":"Metaheuristics.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"The algorithms in Metaheuristics are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"The Rosenbrock function can optimized using the Evolutionary Centers Algorithm ECA() as follows:","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, ECA(), maxiters=100000, maxtime=1000.0)","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Per default Metaheuristics ignores the initial values x0 set in the OptimizationProblem. In order to for GalacticOptim to use x0 we have to set use_initial=true:","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, ECA(), use_initial=true, maxiters=100000, maxtime=1000.0)","category":"page"},{"location":"optimization_packages/metaheuristics/#With-Constraint-Equations","page":"Metaheuristics.jl","title":"With Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"While Metaheuristics.jl supports such constraints, GalacticOptim.jl currently does not relay these constraints.","category":"page"},{"location":"optimization_packages/optim/#Optim.jl","page":"Optim.jl","title":"Optim.jl","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim is Julia package implementing various algorithm to perform univariate and multivariate optimization.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl algorithms are chosen either via NLopt.AlgorithmName() where AlgorithmName can be one of the following:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.NelderMead()\nOptim.SimulatedAnnealing()\nOptim.ParticleSwarm()\nOptim.ConjugateGradient()\nOptim.GradientDescent()\nOptim.BFGS()\nOptim.LBFGS()\nOptim.NGMRES()\nOptim.OACCEL()\nOptim.NewtonTrustRegion()\nOptim.Newton()\nOptim.KrylovTrustRegion()\nOptim.ParticleSwarm()\nOptim.SAMIN()","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Each optimizer also takes special arguments which are outlined in the sections below.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The following special keyword arguments which are not covered by the common solve arguments can be used with Optim.jl optimizers:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"x_tol: Absolute tolerance in changes of the input vector x, in infinity norm. Defaults to 0.0.\ng_tol: Absolute tolerance in the gradient, in infinity norm. Defaults to 1e-8. For gradient free methods, this will control the main convergence tolerance, which is solver specific.\nf_calls_limit: A soft upper limit on the number of objective calls. Defaults to 0 (unlimited).\ng_calls_limit: A soft upper limit on the number of gradient calls. Defaults to 0 (unlimited).\nh_calls_limit: A soft upper limit on the number of Hessian calls. Defaults to 0 (unlimited).\nallow_f_increases: Allow steps that increase the objective value. Defaults to false. Note that, when setting this to true, the last iterate will be returned as the minimizer even if the objective increased.\nstore_trace: Should a trace of the optimization algorithm's state be stored? Defaults to false.\nshow_trace: Should a trace of the optimization algorithm's state be shown on stdout? Defaults to false.\nextended_trace: Save additional information. Solver dependent. Defaults to false.\ntrace_simplex: Include the full simplex in the trace for NelderMead. Defaults to false.\nshow_every: Trace output is printed every show_everyth iteration.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"For a more extensive documentation of all the algorithms and options please consult the  Documentation","category":"page"},{"location":"optimization_packages/optim/#Local-Optimizer","page":"Optim.jl","title":"Local Optimizer","text":"","category":"section"},{"location":"optimization_packages/optim/#Local-Constraint","page":"Optim.jl","title":"Local Constraint","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following local constraint algorithms:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.IPNewton()\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nμ0 specifies the initial barrier penalty coefficient as either a number or :auto\nshow_linesearch is an option to turn on linesearch verbosity.\nDefaults:\nlinesearch::Function = Optim.backtrack_constrained_grad\nμ0::Union{Symbol,Number} = :auto\nshow_linesearch::Bool = false","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can optimized using the Optim.IPNewton() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\ncons= (x,p) -> [x[1]^2 + x[2]^2]\nx0 = zeros(2)\np  = [1.0,100.0]\nprob = OptimizationFunction(rosenbrock, GalacticOptim.AutoForwardDiff();cons= cons)\nprob = GalacticOptim.OptimizationProblem(prob, x0, p, lcons = [-5.0], ucons = [10.0])\nsol = solve(prob, IPNewton())","category":"page"},{"location":"optimization_packages/optim/#Derivative-Free","page":"Optim.jl","title":"Derivative-Free","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Derivative-free optimizers are optimizers that can be used even in cases where no derivatives or automatic differentiation is specified. While they tend to be less efficient than derivative-based optimizers, they can be easily applied to cases where defining derivatives is difficult. Note that while these methods do not support general constraints, all support bounds constraints via lb and ub in the GalacticOptim.OptimizationProblem.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following derivative-free algorithms:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.NelderMead(): Nelder-Mead optimizer\nsolve(problem, NelderMead(parameters, initial_simplex))\nparameters = AdaptiveParameters() or parameters = FixedParameters()\ninitial_simplex = AffineSimplexer()\nDefaults:\nparameters = AdaptiveParameters()\ninitial_simplex = AffineSimplexer()\nOptim.SimulatedAnnealing(): Simulated Annealing\nsolve(problem, SimulatedAnnealing(neighbor, T, p))\nneighbor is a mutating function of the current and proposed x\nT is a function of the current iteration that returns a temperature\np is a function of the current temperature\nDefaults:\nneighbor = default_neighbor!\nT = default_temperature\np = kirkpatrick\nOptim.ParticleSwarm()","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can optimized using the Optim.NelderMead() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"rosenbrock(x, p) =  (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0,100.0]\nprob = GalacticOptim.OptimizationProblem(rosenbrock, x0, p)\nsol = solve(prob, Optim.NelderMead())","category":"page"},{"location":"optimization_packages/optim/#Gradient-Based","page":"Optim.jl","title":"Gradient-Based","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Gradient-based optimizers are optimizers which utilise the gradient information based on derivatives defined or automatic differentiation.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following gradient-based algorithms:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.ConjugateGradient(): Conjugate Gradient Descent\nsolve(problem, ConjugateGradient(alphaguess, linesearch, eta, P, precondprep))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\neta determines the next step direction\nP is an optional preconditioner (for more information, see this source)\nprecondpred is used to update P as the state variable x changes\nDefaults:\nalphaguess = LineSearches.InitialHagerZhang()\nlinesearch = LineSearches.HagerZhang()\neta = 0.4\nP = nothing\nprecondprep = (P, x) -> nothing\nOptim.GradientDescent(): Gradient Descent (a quasi-Newton solver)\nsolve(problem, GradientDescent(alphaguess, linesearch, P, precondprep))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nP is an optional preconditioner (for more information, see this source)\nprecondpred is used to update P as the state variable x changes\nDefaults:\nalphaguess = LineSearches.InitialPrevious()\nlinesearch = LineSearches.HagerZhang()\nP = nothing\nprecondprep = (P, x) -> nothing\nOptim.BFGS(): Broyden-Fletcher-Goldfarb-Shanno algorithm\nsolve(problem, BFGS(alpaguess, linesearch, initial_invH, initial_stepnorm, manifold))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\ninitial_invH specifies an optional initial matrix\ninitial_stepnorm determines that initial_invH is an identity matrix scaled by the value of initial_stepnorm multiplied by the sup-norm of the gradient at the initial point\nmanifold specifies a (Riemannian) manifold on which the function is to be minimized (for more information, consult this source)\navailable manifolds:\nFlat\nSphere\nStiefel\nmeta-manifolds:\nPowerManifold\nProductManifold\ncustom manifolds\nDefaults:\nalphaguess = LineSearches.InitialStatic()\nlinesearch = LineSearches.HagerZhang()\ninitial_invH = nothing\ninitial_stepnorm = nothing\nmanifold = Flat()\nOptim.LBFGS(): Limited-memory Broyden-Fletcher-Goldfarb-Shanno algorithm\nm is the number of history points\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nP is an optional preconditioner (for more information, see this source)\nprecondpred is used to update P as the state variable x changes\nmanifold specifies a (Riemannian) manifold on which the function is to be minimized (for more information, consult this source)\navailable manifolds:\nFlat\nSphere\nStiefel\nmeta-manifolds:\nPowerManifold\nProductManifold\ncustom manifolds\nscaleinvH0: whether to scale the initial Hessian approximation\nDefaults:\nm = 10\nalphaguess = LineSearches.InitialStatic()\nlinesearch = LineSearches.HagerZhang()\nP = nothing\nprecondprep = (P, x) -> nothing\nmanifold = Flat()\nscaleinvH0::Bool = true && (typeof(P) <: Nothing)\nOptim.NGMRES()\nOptim.OACCEL()","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can optimized using the Optim.LD_LBFGS() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"rosenbrock(x, p) =  (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0,100.0]\noptprob = OptimizationFunction(rosenbrock, GalacticOptim.AutoForwardDiff())\nprob = GalacticOptim.OptimizationProblem(optprob, x0, p, lb=[-1.0, -1.0], ub=[0.8, 0.8])\nsol = solve(prob, NLopt.LD_LBFGS())","category":"page"},{"location":"optimization_packages/optim/#Hessian-Based-Second-Order","page":"Optim.jl","title":"Hessian-Based Second Order","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Hessian-based optimization methods are second order optimization methods which use the direct computation of the Hessian. These can converge faster but require fast and accurate methods for calulating the Hessian in order to be appropriate.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following hessian-based algorithms:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.NewtonTrustRegion(): Newton Trust Region method\ninitial_delta: The starting trust region radius\ndelta_hat: The largest allowable trust region radius\neta: When rho is at least eta, accept the step.\nrho_lower: When rho is less than rho_lower, shrink the trust region.\nrho_upper: When rho is greater than rhoupper, grow the trust region (though no greater than deltahat).\nDefaults:\ninitial_delta = 1.0\ndelta_hat = 100.0\neta = 0.1\nrho_lower = 0.25\nrho_upper = 0.75\nOptim.Newton(): Newton's method with line search\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nDefaults:\nalphaguess = LineSearches.InitialStatic()\nlinesearch = LineSearches.HagerZhang()","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can optimized using the Optim.Newton() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"rosenbrock(x, p) =  (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0,100.0]\nf = OptimizationFunction(rosenbrock,ModelingToolkit.AutoModelingToolkit(),x0,p,grad=true,hess=true)\nprob = GalacticOptim.OptimizationProblem(f,x0,p)\nsol = solve(prob,Optim.Newton())","category":"page"},{"location":"optimization_packages/optim/#Hessian-Free-Second-Order","page":"Optim.jl","title":"Hessian-Free Second Order","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Hessian-free methods are methods which perform second order optimization by direct computation of Hessian-vector products (Hv) without requiring the construction of the full Hessian. As such, these methods can perform well for large second order optimization problems, but can require special case when considering conditioning of the Hessian.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following hessian-free algorithms:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.KrylovTrustRegion(): A Newton-Krylov method with Trust Regions\ninitial_delta: The starting trust region radius\ndelta_hat: The largest allowable trust region radius\neta: When rho is at least eta, accept the step.\nrho_lower: When rho is less than rho_lower, shrink the trust region.\nrho_upper: When rho is greater than rhoupper, grow the trust region (though no greater than deltahat).\nDefaults:\ninitial_delta = 1.0\ndelta_hat = 100.0\neta = 0.1\nrho_lower = 0.25\nrho_upper = 0.75","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can optimized using the Optim.KrylovTrustRegion() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"rosenbrock(x, p) =  (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\ncons= (x,p) -> [x[1]^2 + x[2]^2]\nx0 = zeros(2)\np  = [1.0,100.0]\noptprob = OptimizationFunction(rosenbrock, GalacticOptim.AutoForwardDiff();cons= cons)\nprob = GalacticOptim.OptimizationProblem(optprob, x0, p)\nsol = solve(prob, Optim.KrylovTrustRegion())","category":"page"},{"location":"optimization_packages/optim/#Global-Optimizer","page":"Optim.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/optim/#Without-Constraint-Equations","page":"Optim.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The following method in Optim is performing global optimization on problems without constraint equations. It works both with and without lower and upper constraints set by lb and ub in the GalacticOptim.OptimizationProblem.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.ParticleSwarm(): Particle Swarm Optimization\nsolve(problem, ParticleSwarm(lower, upper, n_particles))\nlower/upper are vectors of lower/upper bounds respectively\nn_particles is the number of particles in the swarm\ndefaults to: lower = [], upper = [], n_particles = 0","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can optimized using the Optim.ParticleSwarm() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0,100.0]\nf = OptimizationFunction(rosenbrock)\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb=[-1.0, -1.0], ub=[1.0, 1.0])\nsol = solve(prob, Optim.ParticleSwarm(lower=prob.lb, upper= prob.ub, n_particles=100))","category":"page"},{"location":"optimization_packages/optim/#With-Constraint-Equations","page":"Optim.jl","title":"With Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The following method in Optim is performing global optimization on problems with constraint equations.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.SAMIN(): Simulated Annealing with bounds\nsolve(problem, SAMIN(nt, ns, rt, neps, f_tol, x_tol, coverage_ok, verbosity))\nDefaults:\nnt = 5\nns = 5\nrt = 0.9\nneps = 5\nf_tol = 1e-12\nx_tol = 1e-6\ncoverage_ok = false\nverbosity = 0","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can optimized using the Optim.SAMIN() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"rosenbrock(x, p) =  (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0,100.0]\nf = OptimizationFunction(rosenbrock, GalacticOptim.AutoForwardDiff())\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb=[-1.0, -1.0], ub=[1.0, 1.0])\nsol = solve(prob, Optim.SAMIN())","category":"page"},{"location":"tutorials/rosenbrock/#Rosenbrock-function-examples","page":"Rosenbrock function","title":"Rosenbrock function examples","text":"","category":"section"},{"location":"tutorials/rosenbrock/","page":"Rosenbrock function","title":"Rosenbrock function","text":"using GalacticOptim, Optim, ForwardDiff, Zygote, Test, Random\n\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p  = [1.0, 100.0]\n\nf = OptimizationFunction(rosenbrock, GalacticOptim.AutoForwardDiff())\nl1 = rosenbrock(x0, _p)\nprob = OptimizationProblem(f, x0, _p)\nsol = solve(prob, SimulatedAnnealing())\n@test 10*sol.minimum < l1\n\nRandom.seed!(1234)\nprob = OptimizationProblem(f, x0, _p, lb=[-1.0, -1.0], ub=[0.8, 0.8])\nsol = solve(prob, SAMIN())\n@test 10*sol.minimum < l1\n\nusing CMAEvolutionStrategy\nsol = solve(prob, CMAEvolutionStrategyOpt())\n@test 10*sol.minimum < l1\n\nrosenbrock(x, p=nothing) =  (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\n\nl1 = rosenbrock(x0)\nprob = OptimizationProblem(rosenbrock, x0)\nsol = solve(prob, NelderMead())\n@test 10*sol.minimum < l1\n\ncons= (x,p) -> [x[1]^2 + x[2]^2]\noptprob = OptimizationFunction(rosenbrock, GalacticOptim.AutoForwardDiff();cons= cons)\n\nprob = OptimizationProblem(optprob, x0)\n\nsol = solve(prob, ADAM(0.1), maxiters = 1000)\n@test 10*sol.minimum < l1\n\nsol = solve(prob, BFGS())\n@test 10*sol.minimum < l1\n\nsol = solve(prob, Newton())\n@test 10*sol.minimum < l1\n\nsol = solve(prob, Optim.KrylovTrustRegion())\n@test 10*sol.minimum < l1\n\nprob = OptimizationProblem(optprob, x0, lcons = [-Inf], ucons = [Inf])\nsol = solve(prob, IPNewton())\n@test 10*sol.minimum < l1\n\nprob = OptimizationProblem(optprob, x0, lcons = [-5.0], ucons = [10.0])\nsol = solve(prob, IPNewton())\n@test 10*sol.minimum < l1\n\nprob = OptimizationProblem(optprob, x0, lcons = [-Inf], ucons = [Inf], lb = [-500.0,-500.0], ub=[50.0,50.0])\nsol = solve(prob, IPNewton())\n@test sol.minimum < l1\n\nfunction con2_c(x,p)\n    [x[1]^2 + x[2]^2, x[2]*sin(x[1])-x[1]]\nend\n\noptprob = OptimizationFunction(rosenbrock, GalacticOptim.AutoForwardDiff();cons= con2_c)\nprob = OptimizationProblem(optprob, x0, lcons = [-Inf,-Inf], ucons = [Inf,Inf])\nsol = solve(prob, IPNewton())\n@test 10*sol.minimum < l1\n\ncons_circ = (x,p) -> [x[1]^2 + x[2]^2]\noptprob = OptimizationFunction(rosenbrock, GalacticOptim.AutoForwardDiff();cons= cons_circ)\nprob = OptimizationProblem(optprob, x0, lcons = [-Inf], ucons = [0.25^2])\nsol = solve(prob, IPNewton())\n@test sqrt(cons(sol.minimizer,nothing)[1]) ≈ 0.25 rtol = 1e-6\n\noptprob = OptimizationFunction(rosenbrock, GalacticOptim.AutoZygote())\nprob = OptimizationProblem(optprob, x0)\nsol = solve(prob, ADAM(), maxiters = 1000, progress = false)\n@test 10*sol.minimum < l1\n\nprob = OptimizationProblem(optprob, x0, lb=[-1.0, -1.0], ub=[0.8, 0.8])\nsol = solve(prob, Fminbox())\n@test 10*sol.minimum < l1\n\nprob = OptimizationProblem(optprob, x0, lb=[-1.0, -1.0], ub=[0.8, 0.8])\n@test_broken @test_nowarn sol = solve(prob, SAMIN())\n@test 10*sol.minimum < l1\n\nusing NLopt\nprob = OptimizationProblem(optprob, x0)\nsol = solve(prob, Opt(:LN_BOBYQA, 2))\n@test 10*sol.minimum < l1\n\nsol = solve(prob, Opt(:LD_LBFGS, 2))\n@test 10*sol.minimum < l1\n\nprob = OptimizationProblem(optprob, x0, lb=[-1.0, -1.0], ub=[0.8, 0.8])\nsol = solve(prob, Opt(:LD_LBFGS, 2))\n@test 10*sol.minimum < l1\n\nsol = solve(prob, Opt(:G_MLSL_LDS, 2), nstart=2, local_method = Opt(:LD_LBFGS, 2), maxiters=10000)\n@test 10*sol.minimum < l1\n\n# using MultistartOptimization\n# sol = solve(prob, MultistartOptimization.TikTak(100), local_method = NLopt.LD_LBFGS)\n# @test 10*sol.minimum < l1\n\n# using QuadDIRECT\n# sol = solve(prob, QuadDirect(); splits = ([-0.5, 0.0, 0.5],[-0.5, 0.0, 0.5]))\n# @test 10*sol.minimum < l1\n\nusing Evolutionary\nsol = solve(prob, CMAES(μ =40 , λ = 100),abstol=1e-15)\n@test 10*sol.minimum < l1\n\nusing BlackBoxOptim\nprob = GalacticOptim.OptimizationProblem(optprob, x0, lb=[-1.0, -1.0], ub=[0.8, 0.8])\nsol = solve(prob, BBO())\n@test 10*sol.minimum < l1","category":"page"},{"location":"optimization_packages/mathoptinterface/#MathOptInterface.jl","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"MathOptInterface is Julia abstration layer to interface with variety of mathematical optimization solvers.","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"As of now the GalacticOptim interface to MathOptInterface implents only the maxtime common keyword arguments. An optimizer which is implemented in the MathOptInterface is can be called be called directly if no optimizer options have to be defined. For example using the Ipopt.jl optimizer:","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"sol = solve(prob, Ipopt.Optimizer())","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"The optimizer options are handled in one of two ways. They can either be set via GalacticOptim.MOI.OptimizerWithAttributes() or as keyword argument to solve. For example using the Ipopt.jl optimizer:","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"opt = GalacticOptim.MOI.OptimizerWithAttributes(Ipopt.Optimizer, \"option_name\" => option_value, ...)\nsol = solve(prob, opt)\n\nsol = solve(prob,  Ipopt.Optimizer(); option_name = option_value, ...)","category":"page"},{"location":"optimization_packages/mathoptinterface/#Local-Optimizer","page":"MathOptInterface.jl","title":"Local Optimizer","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/#Local-constraint","page":"MathOptInterface.jl","title":"Local constraint","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/#Ipopt.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"Ipopt.jl (MathOptInterface)","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"Ipopt.Optimizer\nIpopt is a MathOptInterface optimizer, and thus its options are handled via GalacticOptim.MOI.OptimizerWithAttributes(Ipopt.Optimizer, \"option_name\" => option_value, ...)\nThe full list of optimizer options can be found in the Ipopt Documentation","category":"page"},{"location":"optimization_packages/mathoptinterface/#KNITRO.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"KNITRO.jl (MathOptInterface)","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"KNITRO.Optimizer\nKNITRO is a MathOptInterface optimizer, and thus its options are handled via GalacticOptim.MOI.OptimizerWithAttributes(KNITRO.Optimizer, \"option_name\" => option_value, ...)\nThe full list of optimizer options can be found in the KNITRO Documentation","category":"page"},{"location":"optimization_packages/mathoptinterface/#AmplNLWriter.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"AmplNLWriter.jl (MathOptInterface)","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"AmplNLWriter.Optimizer\nAmplNLWriter is a MathOptInterface optimizer, and thus its options are handled via GalacticOptim.MOI.OptimizerWithAttributes(AmplNLWriter.Optimizer(algname), \"option_name\" => option_value, ...)\nPossible algnames are:\nBonmin_jll.amplexe\nCouenne_jll.amplexe\nIpopt_jll.amplexe\nSHOT_jll.amplexe","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"To use one of the JLLs, they must be added first. For example: Pkg.add(\"Bonmin_jll\").","category":"page"},{"location":"optimization_packages/mathoptinterface/#Juniper.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"Juniper.jl (MathOptInterface)","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"Juniper.Optimizer\nJuniper is a MathOptInterface optimizer, and thus its options are handled via GalacticOptim.MOI.OptimizerWithAttributes(Ipopt.Optimizer, \"option_name\" => option_value, ...)\nJuniper requires the choice of a relaxation method nl_solver which must be a MathOptInterface-based optimizer","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"using GalacticOptim, ForwardDiff\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p  = [1.0, 100.0]\n\nf = OptimizationFunction(rosenbrock, GalacticOptim.AutoForwardDiff())\nprob = GalacticOptim.OptimizationProblem(f, x0, _p)\n\nusing Juniper, Ipopt\noptimizer = Juniper.Optimizer\n# Choose a relaxation method\nnl_solver = GalacticOptim.MOI.OptimizerWithAttributes(Ipopt.Optimizer, \"print_level\"=>0)\n\nopt = GalacticOptim.MOI.OptimizerWithAttributes(optimizer, \"nl_solver\"=>nl_solver)\nsol = solve(prob, opt)","category":"page"},{"location":"optimization_packages/mathoptinterface/#BARON.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"BARON.jl (MathOptInterface)","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"BARON.Optimizer\nBARON is a MathOptInterface optimizer, and thus its options are handled via GalacticOptim.MOI.OptimizerWithAttributes(BARON.Optimizer, \"option_name\" => option_value, ...)\nThe full list of optimizer options can be found in the BARON Documentation","category":"page"},{"location":"optimization_packages/mathoptinterface/#Gradient-Based","page":"MathOptInterface.jl","title":"Gradient-Based","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/#Ipopt.jl-(MathOptInterface)-2","page":"MathOptInterface.jl","title":"Ipopt.jl (MathOptInterface)","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"Ipopt.Optimizer\nIpopt is a MathOptInterface optimizer, and thus its options are handled via GalacticOptim.MOI.OptimizerWithAttributes(Ipopt.Optimizer, \"option_name\" => option_value, ...)\nThe full list of optimizer options can be found in the Ipopt Documentation","category":"page"},{"location":"optimization_packages/mathoptinterface/#Global-Optimizer","page":"MathOptInterface.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/#With-Constraint-Equations","page":"MathOptInterface.jl","title":"With Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/#Alpine.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"Alpine.jl (MathOptInterface)","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"Alpine.Optimizer\nAlpine is a MathOptInterface optimizer, and thus its options are handled via GalacticOptim.MOI.OptimizerWithAttributes(Alpine.Optimizer, \"option_name\" => option_value, ...)\nThe full list of optimizer options can be found in the Alpine Documentation","category":"page"},{"location":"tutorials/minibatch/#Minibatch-examples","page":"Minibatch","title":"Minibatch examples","text":"","category":"section"},{"location":"tutorials/minibatch/","page":"Minibatch","title":"Minibatch","text":"using DiffEqFlux, GalacticOptim, OrdinaryDiffEq\n\nfunction newtons_cooling(du, u, p, t)\n    temp = u[1]\n    k, temp_m = p\n    du[1] = dT = -k*(temp-temp_m)\n  end\n\nfunction true_sol(du, u, p, t)\n    true_p = [log(2)/8.0, 100.0]\n    newtons_cooling(du, u, true_p, t)\nend\n\nfunction dudt_(u,p,t)\n    ann(u, p).* u\nend\n\ncb = function (p,l,pred;doplot=false) #callback function to observe training\n    display(l)\n    # plot current prediction against data\n    if doplot\n      pl = scatter(t,ode_data[1,:],label=\"data\")\n      scatter!(pl,t,pred[1,:],label=\"prediction\")\n      display(plot(pl))\n    end\n    return false\nend\n\nu0 = Float32[200.0]\ndatasize = 30\ntspan = (0.0f0, 1.5f0)\n\nt = range(tspan[1], tspan[2], length=datasize)\ntrue_prob = ODEProblem(true_sol, u0, tspan)\node_data = Array(solve(true_prob, Tsit5(), saveat=t))\n\nann = FastChain(FastDense(1,8,tanh), FastDense(8,1,tanh))\npp = initial_params(ann)\nprob = ODEProblem{false}(dudt_, u0, tspan, pp)\n\nfunction predict_adjoint(fullp, time_batch)\n    Array(solve(prob, Tsit5(), p = fullp, saveat = time_batch))\nend\n\nfunction loss_adjoint(fullp, batch, time_batch)\n    pred = predict_adjoint(fullp,time_batch)\n    sum(abs2, batch .- pred), pred\nend\n\n\nk = 10\ntrain_loader = Flux.Data.DataLoader((ode_data, t), batchsize = k)\n\nnumEpochs = 300\nl1 = loss_adjoint(pp, train_loader.data[1], train_loader.data[2])[1]\n\noptfun = OptimizationFunction((θ, p, batch, time_batch) -> loss_adjoint(θ, batch, time_batch), GalacticOptim.AutoZygote())\noptprob = OptimizationProblem(optfun, pp)\nusing IterTools: ncycle\nres1 = GalacticOptim.solve(optprob, ADAM(0.05), ncycle(train_loader, numEpochs), cb = cb)\n@test 10res1.minimum < l1","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/#CMAEvolutionStrategy.jl","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"CMAEvolutionStrategy is a Julia package implementing the Covariance Matrix Adaptation Evolution Strategy algorithm. ","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"The CMAEvolutionStrategy algorithm is called by CMAEvolutionStrategyOpt()","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/#Global-Optimizer","page":"CMAEvolutionStrategy.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/#Without-Constraint-Equations","page":"CMAEvolutionStrategy.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"The method in CMAEvolutionStrategy is performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"The Rosenbrock function can optimized using the CMAEvolutionStrategyOpt() as follows:","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, CMAEvolutionStrategyOpt())","category":"page"},{"location":"optimization_packages/nonconvex/#Nonconvex.jl","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"","category":"section"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"Nonconvex is a is a Julia package implementing and wrapping nonconvex constrained optimization algorithms.","category":"page"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"A Nonconvex algorithm is called using one of the following:","category":"page"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"Method of moving asymptotes (MMA):\nMMA87()\nMMA02()\nIpopt:\nIpoptAlg()\nNLopt:\nNLoptAlg(solver) where solver can be any of the NLopt algorithms\nAugmented Lagrangian algorithm:\nAugLag()\nonly works with constraints\nMixed integer nonlinear programming (MINLP):\nJuniper + Ipopt: JuniperIpoptAlg()\nPavito + Ipopt + Cbc: PavitoIpoptCbcAlg()\nMulti-start optimization:\nHyperoptAlg(subsolver) where subalg can be any of the described Nonconvex algorithm\nSurrogate-assisted Bayesian optimization\nBayesOptAlg(subsolver) where subalg can be any of the described Nonconvex algorithm\nMultiple Trajectory Search\nMTSAlg()","category":"page"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"When performing optimizing a combination of integer and floating-point parameters the integer keyword has to be set. It takes a boolean vector indicating which parameter is an integer.","category":"page"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"Some optimizer may require further options to be defined in order to work.","category":"page"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"The currently available algorithms are listed here","category":"page"},{"location":"optimization_packages/nonconvex/#Global-Optimizer","page":"Nonconvex.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/nonconvex/#Without-Constraint-Equations","page":"Nonconvex.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"The algorithms in Nonconvex are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"The Rosenbrock function can optimized using the Method of moving asymptotes algorithm MMA02() as follows:","category":"page"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, MMA02(), maxiters=100000, maxtime=1000.0)","category":"page"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"The options of for a sub-algorithm are passed simply as a NamedTuple and GalactcOptim infers the correct Nonconvex options struct:","category":"page"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, HyperoptAlg(IpoptAlg()), sub_options=(;max_iter=100))","category":"page"},{"location":"optimization_packages/nonconvex/#With-Constraint-Equations","page":"Nonconvex.jl","title":"With Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"While Nonconvex.jl supports such constraints, GalacticOptim.jl currently does not relay these constraints.","category":"page"},{"location":"API/optimization_problem/#Defining-OptimizationProblems","page":"OptimizationProblem","title":"Defining OptimizationProblems","text":"","category":"section"},{"location":"API/optimization_problem/","page":"OptimizationProblem","title":"OptimizationProblem","text":"All optimizations start by defining an OptimizationProblem as follows:","category":"page"},{"location":"API/optimization_problem/","page":"OptimizationProblem","title":"OptimizationProblem","text":"OptimizationProblem(f, x, p = DiffEqBase.NullParameters(),;\n                    lb = nothing,\n                    ub = nothing,\n                    lcons = nothing,\n                    ucons = nothing,\n                    kwargs...)","category":"page"},{"location":"API/optimization_problem/","page":"OptimizationProblem","title":"OptimizationProblem","text":"Formally, the OptimizationProblem finds the minimum of f(x,p) with an initial condition x. The parameters p are optional. lb and ub are arrays matching the size of x, which stand for the lower and upper bounds of x, respectively.","category":"page"},{"location":"API/optimization_problem/","page":"OptimizationProblem","title":"OptimizationProblem","text":"f is an OptimizationFunction, as defined here. If f is a standard Julia function, it is automatically converted into an OptimizationFunction with NoAD(), i.e., no automatic generation of the derivative functions.","category":"page"},{"location":"API/optimization_problem/","page":"OptimizationProblem","title":"OptimizationProblem","text":"Any extra keyword arguments are captured to be sent to the optimizers.","category":"page"},{"location":"optimization_packages/speedmapping/#SpeedMapping.jl","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"","category":"section"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"SpeedMapping accelerates the convergence of a mapping to a fixed point by the Alternating cyclic extrapolation algorithm which can also perform multivariate optimization based on the gradient function.","category":"page"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"The SpeedMapping algorithm is called by SpeedMappingOpt()","category":"page"},{"location":"optimization_packages/speedmapping/#Global-Optimizer","page":"SpeedMapping.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/speedmapping/#Without-Constraint-Equations","page":"SpeedMapping.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"The method in SpeedMapping is performing optimization on problems without constraint equations. Lower and upper constraints set by lb and ub in the OptimizationProblem are optional.","category":"page"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"If no AD backend is defined via OptimizationFunction the gradient is calculated via SpeedMapping's ForwardDiff AD backend.","category":"page"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"The Rosenbrock function can be optimized using the SpeedMappingOpt() with and without bound as follows:","category":"page"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, GalacticOptim.AutoForwardDiff())\nprob = OptimizationProblem(f, x0, _p)\nsol = solve(prob,SpeedMappingOpt())\n\nprob = OptimizationProblem(f, x0, _p;lb=[0.0,0.0], ub=[1.0,1.0])\nsol = solve(prob,SpeedMappingOpt())","category":"page"},{"location":"optimization_packages/flux/#Flux.jl","page":"Flux.jl","title":"Flux.jl","text":"","category":"section"},{"location":"optimization_packages/flux/","page":"Flux.jl","title":"Flux.jl","text":"Flux.Optimise.Descent: Classic gradient descent optimizer with learning rate\nsolve(problem, Descent(η))\nη is the learning rate\nDefaults:\nη = 0.1\nFlux.Optimise.Momentum: Classic gradient descent optimizer with learning rate and momentum\nsolve(problem, Momentum(η, ρ))\nη is the learning rate\nρ is the momentum\nDefaults:\nη = 0.01\nρ = 0.9\nFlux.Optimise.Nesterov: Gradient descent optimizer with learning rate and Nesterov momentum\nsolve(problem, Nesterov(η, ρ))\nη is the learning rate\nρ is the Nesterov momentum\nDefaults:\nη = 0.01\nρ = 0.9\nFlux.Optimise.RMSProp: RMSProp optimizer\nsolve(problem, RMSProp(η, ρ))\nη is the learning rate\nρ is the momentum\nDefaults:\nη = 0.001\nρ = 0.9\nFlux.Optimise.ADAM: ADAM optimizer\nsolve(problem, ADAM(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nFlux.Optimise.RADAM: Rectified ADAM optimizer\nsolve(problem, RADAM(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nFlux.Optimise.AdaMax: AdaMax optimizer\nsolve(problem, AdaMax(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nFlux.Optimise.ADAGRad: ADAGrad optimizer\nsolve(problem, ADAGrad(η))\nη is the learning rate\nDefaults:\nη = 0.1\nFlux.Optimise.ADADelta: ADADelta optimizer\nsolve(problem, ADADelta(ρ))\nρ is the gradient decay factor\nDefaults:\nρ = 0.9\nFlux.Optimise.AMSGrad: AMSGrad optimizer\nsolve(problem, AMSGrad(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nFlux.Optimise.NADAM: Nesterov variant of the ADAM optimizer\nsolve(problem, NADAM(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nFlux.Optimise.ADAMW: ADAMW optimizer\nsolve(problem, ADAMW(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\ndecay is the decay to weights\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\ndecay = 0","category":"page"},{"location":"optimization_packages/nomad/#NOMAD.jl","page":"NOMAD.jl","title":"NOMAD.jl","text":"","category":"section"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"NOMAD is Julia package interfacing to NOMAD,which is a C++ implementation of the Mesh Adaptive Direct Search algorithm (MADS), designed for difficult blackbox optimization problems. These problems occur when the functions defining the objective and constraints are the result of costly computer simulations. NOMAD.jl documentation","category":"page"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"The NOMAD algorithm is called by NOMADOpt()","category":"page"},{"location":"optimization_packages/nomad/#Global-Optimizer","page":"NOMAD.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/nomad/#Without-Constraint-Equations","page":"NOMAD.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"The method in NOMAD is performing global optimization on problems both with and without constraint equations. Currently however, linear and nonlinear constraints  defined in GalacticOPtim are not passed.","category":"page"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"NOMAD works both with and without lower and upper boxconstraints set by lb and ub in the OptimizationProblem.","category":"page"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"The Rosenbrock function can optimized using the NOMADOpt() with and without boxcontraints as follows:","category":"page"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\n\nprob = OptimizationProblem(f, x0, _p)\nsol = GalacticOptim.solve(prob,NOMADOpt())\n\nprob = OptimizationProblem(f, x0, _p, lb = [-1.0,-1.0], ub = [1.5,1.5])\nsol = GalacticOptim.solve(prob,NOMADOpt())","category":"page"},{"location":"optimization_packages/multistartoptimization/#MultiStartOptimization.jl","page":"MultistartOptimization.jl","title":"MultiStartOptimization.jl","text":"","category":"section"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"MultistartOptimization is a is a Julia package implementing a global optimization multistart method which performs local optimization after choosing multiple starting points.","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"MultistartOptimization requires both a global and local method to be defined. The global multistart method chooses a set of initial starting points from where local the local method starts from.","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"Currently, only one global method (TikTak) is implemented and called by MultiStartOptimization.TikTak(n) where n is the number of initial Sobol points. ","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"Currently, the local methods can be one of the algotithms implemented in NLopt.jl. ","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"note: Note\nIf you checkout the master branch of MultiStartOptimization or have version >=0.1.3 you can use all optimizers found in the GalacticOptim which work with an initial parameter set. See an example of this below.","category":"page"},{"location":"optimization_packages/multistartoptimization/#Global-Optimizer","page":"MultistartOptimization.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/multistartoptimization/#Without-Constraint-Equations","page":"MultistartOptimization.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"The methods in MultistartOptimization is performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"The Rosenbrock function can optimized using MultistartOptimization.TikTak() with 100 initial points and the local method NLopt.LD_LBFGS() as follows:","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, MultistartOptimization.TikTak(100), local_method = NLopt.LD_LBFGS())","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"If you have checked out the master branch MultiStartOptimization version 0.1.2 or have version >=0.1.3 you can use any GalactimOptim optimizers you like. The global method of the MultiStartOptimization is a positional argument and if the given method has a local method it can be easily defined via the local_method keyword argument as you would without MultiStartOptimization. This for example means we can perform a multistartoptimization with LBFGS as the optimizer using either the NLopt.jl or Optim.jl implementation as follows. Moreover, this interface allows you access and adjust all the optimizer settings as you normally would:","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, MultistartOptimization.TikTak(100), NLopt.LD_LBFGS())\nsol = solve(prob, MultistartOptimization.TikTak(100), LBFGS())","category":"page"},{"location":"API/optimization_function/#optfunction","page":"OptimizationFunction","title":"OptimizationFunction","text":"","category":"section"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"The OptimizationFunction type is a function type that holds all of the extra differentiation data required to do fast and accurate optimization. The signature for the constructor is:","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"OptimizationFunction{iip}(f,adtype=NoAD();\n                          grad=nothing,\n                          hess=nothing,\n                          hv=nothing,\n                          cons=nothing,\n                          cons_j=nothing,\n                          cons_h=nothing)","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"The keyword arguments are as follows:","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"grad: Gradient\nhess: Hessian\nhv: Hessian vector products hv(du,u,p,t,v) = H*v\ncons: Constraint function\ncons_j\ncons_h","category":"page"},{"location":"API/optimization_function/#Defining-Optimization-Functions-Via-AD","page":"OptimizationFunction","title":"Defining Optimization Functions Via AD","text":"","category":"section"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"While using the keyword arguments gives the user control over defining all of the possible functions, the simplest way to handle the generation of an OptimizationFunction is by specifying an AD type. By doing so, this will automatically fill in all of the extra functions. For example,","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"OptimizationFunction(f,AutoZygote())","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"will use Zygote.jl to define all of the necessary functions. Note that if any functions are defined directly, the auto-AD definition does not overwrite the user's choice.","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"The choices for the auto-AD fill-ins with quick descriptions are:","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"AutoForwardDiff(): The fastest choice for small optimizations\nAutoReverseDiff(compile=false): A fast choice for large scalar optimizations\nAutoTracker(): Like ReverseDiff but GPU-compatible\nAutoZygote(): The fastest choice\nAutoFiniteDiff(): Finite differencing, not optimal but always applicable\nAutoModelingToolkit(): The fastest choice for large scalar optimizations","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"The following sections describe the Auto-AD choices in detail.","category":"page"},{"location":"API/optimization_function/#AutoForwardDiff","page":"OptimizationFunction","title":"AutoForwardDiff","text":"","category":"section"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"This uses the ForwardDiff.jl package. It is the fastest choice for small systems, especially with heavy scalar interactions. It is easy to use and compatible with most pure is Julia functions which have loose type restrictions. However, because it's forward-mode, it scales poorly in comparison to other AD choices. Hessian construction is suboptimal as it uses the forward-over-forward approach.","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"Compatible with GPUs\nCompatible with Hessian-based optimization\nCompatible with Hv-based optimization\nCompatible with constraints","category":"page"},{"location":"API/optimization_function/#AutoReverseDiff","page":"OptimizationFunction","title":"AutoReverseDiff","text":"","category":"section"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"This uses the ReverseDiff.jl package. AutoReverseDiff has a default argument, compile, which denotes whether the reverse pass should be compiled. compile should only be set to true if f contains no branches (if statements, while loops) otherwise it can produce incorrect derivatives!.","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"AutoReverseDiff is generally applicable to many pure Julia codes, and with compile=true it is one of the fastest options on code with heavy scalar interactions. Hessian calculations are fast by mixing ForwardDiff with ReverseDiff for forward-over-reverse. However, its performance can falter when compile=false.","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"Not compatible with GPUs\nCompatible with Hessian-based optimization by mixing with ForwardDiff\nCompatible with Hv-based optimization by mixing with ForwardDiff\nNot compatible with constraint functions","category":"page"},{"location":"API/optimization_function/#AutoTracker","page":"OptimizationFunction","title":"AutoTracker","text":"","category":"section"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"This uses the Tracker.jl package. Generally slower than ReverseDiff, it is generally applicable to many pure Julia codes.","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"Compatible with GPUs\nNot compatible with Hessian-based optimization\nNot compatible with Hv-based optimization\nNot compatible with constraint functions","category":"page"},{"location":"API/optimization_function/#AutoZygote","page":"OptimizationFunction","title":"AutoZygote","text":"","category":"section"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"This uses the Zygote.jl package. This is the staple reverse-mode AD that handles a large portion of Julia with good efficiency. Hessian construction is fast via forward-over-reverse mixing ForwardDiff.jl with Zygote.jl","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"Compatible with GPUs\nCompatible with Hessian-based optimization via ForwardDiff\nCompatible with Hv-based optimization via ForwardDiff\nNot compatible with constraint functions","category":"page"},{"location":"API/optimization_function/#AutoFiniteDiff","page":"OptimizationFunction","title":"AutoFiniteDiff","text":"","category":"section"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"This uses FiniteDiff.jl. While to necessarily the most efficient in any case, this is the only choice that doesn't require the f function to be automatically differentiable, which means it applies to any choice. However, because it's using finite differencing, one needs to be careful as this procedure introduces numerical error into the derivative estimates.","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"Compatible with GPUs\nCompatible with Hessian-based optimization\nCompatible with Hv-based optimization\nNot compatible with constraint functions","category":"page"},{"location":"API/optimization_function/#AutoModelingToolkit","page":"OptimizationFunction","title":"AutoModelingToolkit","text":"","category":"section"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"This uses the ModelingToolkit.jl symbolic system for automatically converting the f function into a symbolic equation and uses symbolic differentiation in order to generate a fast derivative code. Note that this will also compile a new version of your f function that is automatically optimized. Because of the required symbolic analysis, the state and parameters are required in the function definition, i.e.:","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"OptimizationFunction(f,AutoModelingToolkit(),x0,p,\n                     grad = false, hess = false, sparse = false,\n                     checkbounds = false,\n                     linenumbers = true,\n                     parallel=SerialForm(),\n                     kwargs...)","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"The special keyword arguments are as follows:","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"grad: whether to symbolically generate the gradient function.\nhess: whether to symbolically generate the Hessian function.\nsparse: whether to use sparsity detection in the Hessian.\ncheckbounds: whether to perform bounds checks in the generated code.\nlinenumbers: whether to include line numbers in the generated code.\nparallel: whether to automatically parallelize the calculations.","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"For more information, see the ModelingToolkit.jl OptimizationSystem documentation","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"Summary:","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"Not compatible with GPUs\nCompatible with Hessian-based optimization\nNot compatible with Hv-based optimization\nNot compatible with constraint functions","category":"page"},{"location":"API/modelingtoolkit/#ModelingToolkit-Integration","page":"ModelingToolkit Integration","title":"ModelingToolkit Integration","text":"","category":"section"},{"location":"API/modelingtoolkit/","page":"ModelingToolkit Integration","title":"ModelingToolkit Integration","text":"GalacticOptim.jl is heavily integrated with the ModelingToolkit.jl symbolic system for symbolic-numeric optimizations. It provides a front-end for automating the construction, parallelization, and optimization of code. Optimizers can better interface with the extra symbolic information provided by the system.","category":"page"},{"location":"API/modelingtoolkit/","page":"ModelingToolkit Integration","title":"ModelingToolkit Integration","text":"There are two ways that the user interacts with ModelingToolkit.jl. One can use OptimizationFunction with AutoModelingToolkit for automatically transforming numerical codes into symbolic codes. See the OptimizationFunction documentation for more details.","category":"page"},{"location":"API/modelingtoolkit/","page":"ModelingToolkit Integration","title":"ModelingToolkit Integration","text":"Secondly, one can generate OptimizationProblems for use in GalacticOptim.jl from purely a symbolic front-end. This is the form users will encounter when using ModelingToolkit.jl directly, and its also the form supplied by domain-specific languages. For more information, see the OptimizationSystem documentation.","category":"page"},{"location":"tutorials/symbolic/#Symbolic-Problem-Building-with-ModelingToolkit","page":"Symbolic Modeling","title":"Symbolic Problem Building with ModelingToolkit","text":"","category":"section"},{"location":"tutorials/symbolic/","page":"Symbolic Modeling","title":"Symbolic Modeling","text":"using ModelingToolkit, GalacticOptim\r\n\r\n@variables x y\r\n@parameters a b\r\nloss = (a - x)^2 + b * (y - x^2)^2\r\nsys = OptimizationSystem(loss,[x,y],[a,b])\r\n\r\nu0 = [\r\n    x=>1.0\r\n    y=>2.0\r\n]\r\np = [\r\n    a => 6.0\r\n    b => 7.0\r\n]\r\n\r\nprob = OptimizationProblem(sys,u0,p,grad=true,hess=true)\r\nsolve(prob,Newton())","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Modeling","title":"Symbolic Modeling","text":"Needs text but it's super cool and auto-parallelizes and sparsifies too. Plus you can hierarchically nest systems to have it generate huge optimization problems. Check out the ModelingToolkit.jl OptimizationSystem documentation for more information.","category":"page"},{"location":"optimization_packages/gcmaes/#GCMAES.jl","page":"GCMAES.jl","title":"GCMAES.jl","text":"","category":"section"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"GCMAES is a Julia package implementing the Gradient-based Covariance Matrix Adaptation Evolutionary Strategy which can utilize the gradient information to speed up the optimization process.","category":"page"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"The GCMAES algorithm is called by GCMAESOpt() and the initial search variance is set as a keyword argument σ0 (default: σ0 = 0.2)","category":"page"},{"location":"optimization_packages/gcmaes/#Global-Optimizer","page":"GCMAES.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/gcmaes/#Without-Constraint-Equations","page":"GCMAES.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"The method in GCMAES is performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"The Rosenbrock function can optimized using the GCMAESOpt() without utilizing the gradient information as follows:","category":"page"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, GCMAESOpt())","category":"page"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"We can also utilise the gradient information of the optimization problem to aid the optimization as follows:","category":"page"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, GalacticOptim.ForwardDiff)\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, GCMAESOpt())","category":"page"},{"location":"optimization_packages/evolutionary/#Evolutionary.jl","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"","category":"section"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"Evolutionary is a Julia package implementing various evolutionary and genetic algorithm.","category":"page"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"A Evolutionary algorithm is called by one of the following:","category":"page"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"Evolutionary.GA(): Genetic Algorithm optimizer\nEvolutionary.DE(): Differential Evolution optimizer\nEvolutionary.ES(): Evolution Strategy algorithm\nEvolutionary.CMAES(): Covariance Matrix Adaptation Evolution Strategy algorithm","category":"page"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"Algorithm specific options are defined as kwargs. See the respective documentation for more detail.","category":"page"},{"location":"optimization_packages/evolutionary/#Global-Optimizer","page":"Evolutionary.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/evolutionary/#Without-Constraint-Equations","page":"Evolutionary.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"The methods in Evolutionary are performing global optimization on problems without constraint equations. These methods work both with and without lower and upper constraints set by lb and ub in the OptimizationProblem.","category":"page"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"The Rosenbrock function can optimized using the Evolutionary.CMAES() as follows:","category":"page"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, Evolutionary.CMAES(μ =40 , λ = 100))","category":"page"},{"location":"optimization_packages/quaddirect/#QuadDIRECT.jl","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"","category":"section"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"QuadDIRECT is a Julia package implementing QuadDIRECT algorithm (inspired by DIRECT and MCS). ","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"The QuadDIRECT algorithm is called using QuadDirect(). ","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"Also note that QuadDIRECT should (for now) be installed by doing:","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"] add https://github.com/timholy/QuadDIRECT.jl.git","category":"page"},{"location":"optimization_packages/quaddirect/#Global-Optimizer","page":"QuadDIRECT.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/quaddirect/#Without-Constraint-Equations","page":"QuadDIRECT.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"The algorithm in QuadDIRECT is performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"Furthermore, QuadDirect requires splits which is a list of 3-vectors with initial locations at which to evaluate the function (the values must be in strictly increasing order and lie within the specified bounds) such that solve(problem, QuadDirect(), splits).","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"The Rosenbrock function can optimized using the QuadDirect() as follows:","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = GalacticOptim.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsolve(prob, QuadDirect(), splits = ([-0.9, 0, 0.9], [-0.8, 0, 0.8]))","category":"page"},{"location":"tutorials/intro/#Basic-usage","page":"Basic usage","title":"Basic usage","text":"","category":"section"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"In this tutorial we introduce the basics of GalcticOptim.jl by showing how to easily mix local optimizers from Optim.jl and global optimizers from BlackBoxOptim.jl on the Rosenbrock equation. The simplest copy-pasteable code to get started is the following:","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":" using GalacticOptim, Optim\n rosenbrock(x,p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\n x0 = zeros(2)\n p  = [1.0,100.0]\n\n prob = OptimizationProblem(rosenbrock,x0,p)\n sol = solve(prob,NelderMead())\n\n\n using BlackBoxOptim\n prob = OptimizationProblem(rosenbrock, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\n sol = solve(prob,BBO_adaptive_de_rand_1_bin_radiuslimited())","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"Note that Optim.jl is a core dependency of GalaticOptim.jl. However, BlackBoxOptim.jl is not and must already be installed (see the list above).","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"The output of the first optimization task (with the NelderMead() algorithm) is given below:","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"* Status: success\n\n* Candidate solution\n   Final objective value:     3.525527e-09\n\n* Found with\n   Algorithm:     Nelder-Mead\n\n* Convergence measures\n   √(Σ(yᵢ-ȳ)²)/n ≤ 1.0e-08\n\n* Work counters\n   Seconds run:   0  (vs limit Inf)\n   Iterations:    60\n   f(x) calls:    118","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"We can also explore other methods in a similar way:","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"using ForwardDiff\nf = OptimizationFunction(rosenbrock, GalacticOptim.AutoForwardDiff())\nprob = OptimizationProblem(f, x0, p)\nsol = solve(prob,BFGS())","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"For instance, the above optimization task produces the following output:","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"* Status: success\n\n* Candidate solution\n   Final objective value:     7.645684e-21\n\n* Found with\n   Algorithm:     BFGS\n\n* Convergence measures\n   |x - x'|               = 3.48e-07 ≰ 0.0e+00\n   |x - x'|/|x'|          = 3.48e-07 ≰ 0.0e+00\n   |f(x) - f(x')|         = 6.91e-14 ≰ 0.0e+00\n   |f(x) - f(x')|/|f(x')| = 9.03e+06 ≰ 0.0e+00\n   |g(x)|                 = 2.32e-09 ≤ 1.0e-08\n\n* Work counters\n   Seconds run:   0  (vs limit Inf)\n   Iterations:    16\n   f(x) calls:    53\n   ∇f(x) calls:   53","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":" prob = OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\n sol = solve(prob, Fminbox(GradientDescent()))","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"The examples clearly demonstrate that GalacticOptim.jl provides an intuitive way of specifying optimization tasks and offers a relatively easy access to a wide range of optimization algorithms.","category":"page"},{"location":"#GalacticOptim.jl","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl","text":"","category":"section"},{"location":"","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl: Unified Global Optimization Package","text":"GalacticOptim.jl is a package with a scope that is beyond your normal global optimization package. GalacticOptim.jl seeks to bring together all of the optimization packages it can find, local and global, into one unified Julia interface. This means, you learn one package and you learn them all! GalacticOptim.jl adds a few high-level features, such as integrating with automatic differentiation, to make its usage fairly simple for most cases, while allowing all of the options in a single unified interface.","category":"page"},{"location":"#Note:-The-package-is-still-in-active-development.","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"Note: The package is still in active development.","text":"","category":"section"},{"location":"#Installation","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"Installation","text":"","category":"section"},{"location":"","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl: Unified Global Optimization Package","text":"Assuming that you already have Julia correctly installed, it suffices to import GalacticOptim.jl in the standard way:","category":"page"},{"location":"","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl: Unified Global Optimization Package","text":"import Pkg; Pkg.add(\"GalacticOptim\")","category":"page"},{"location":"","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl: Unified Global Optimization Package","text":"The packages relevant to the core functionality of GalacticOptim.jl will be imported accordingly and, in most cases, you do not have to worry about the manual installation of dependencies. However, you will need to add the specific optimizer packages.","category":"page"},{"location":"#Overview-of-the-Optimizers","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"Overview of the Optimizers","text":"","category":"section"},{"location":"","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl: Unified Global Optimization Package","text":"Package Local Gradient-Based Local Hessian-Based Local Derivative-Free Local Constrained Global Unconstrained Global Constrained\nBlackBoxOptim ❌ ❌ ❌ ❌ ✅ ❌\nCMAEvolutionaryStrategy ❌ ❌ ❌ ❌ ✅ ❌\nEvolutionary ❌ ❌ ❌ ❌ ✅ 🟡\nFlux ✅ ❌ ❌ ❌ ❌ ❌\nGCMAES ❌ ❌ ❌ ❌ ✅ ❌\nMathOptInterface ✅ ✅ ✅ ✅ ✅ 🟡\nMultistartOptimization ❌ ❌ ❌ ❌ ✅ ❌\nMetaheuristics ❌ ❌ ❌ ❌ ✅ 🟡\nNOMAD ❌ ❌ ❌ ❌ ✅ 🟡\nNLopt ✅ ❌ ✅ 🟡 ✅ 🟡\nNonconvex ✅ ✅ ✅ 🟡 ✅ 🟡\nOptim ✅ ✅ ✅ ✅ ✅ ✅\nQuadDIRECT ❌ ❌ ❌ ❌ ✅ ❌","category":"page"},{"location":"","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl: Unified Global Optimization Package","text":"✅ = supported","category":"page"},{"location":"","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl: Unified Global Optimization Package","text":"🟡 = supported in downstream library but not yet implemented in GalacticOptim; PR to add this functionality are welcome","category":"page"},{"location":"","page":"GalacticOptim.jl: Unified Global Optimization Package","title":"GalacticOptim.jl: Unified Global Optimization Package","text":"❌ = not supported","category":"page"}]
}
