var documenterSearchIndex = {"docs":
[{"location":"optimization_packages/blackboxoptim/#BlackBoxOptim.jl","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"","category":"section"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"BlackBoxOptim is a Julia package implementing (Meta-)heuristic/stochastic algorithms that do not require for the optimized function to be differentiable.","category":"page"},{"location":"optimization_packages/blackboxoptim/#Installation:-OptimizationBBO.jl","page":"BlackBoxOptim.jl","title":"Installation: OptimizationBBO.jl","text":"","category":"section"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"To use this package, install the OptimizationBBO package:","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"import Pkg; Pkg.add(\"OptimizationBBO\")","category":"page"},{"location":"optimization_packages/blackboxoptim/#Global-Optimizers","page":"BlackBoxOptim.jl","title":"Global Optimizers","text":"","category":"section"},{"location":"optimization_packages/blackboxoptim/#Without-Constraint-Equations","page":"BlackBoxOptim.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The algorithms in BlackBoxOptim are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"A BlackBoxOptim algorithm is called by BBO_ prefix followed by the algorithm name:","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Natural Evolution Strategies:\nSeparable NES: BBO_separable_nes()\nExponential NES: BBO_xnes()\nDistance-weighted Exponential NES: BBO_dxnes()\nDifferential Evolution optimizers, 5 different:\nAdaptive DE/rand/1/bin: BBO_adaptive_de_rand_1_bin()\nAdaptive DE/rand/1/bin with radius limited sampling: BBO_adaptive_de_rand_1_bin_radiuslimited()\nDE/rand/1/bin: BBO_de_rand_1_bin()\nDE/rand/1/bin with radius limited sampling (a type of trivial geography): BBO_de_rand_1_bin_radiuslimited()\nDE/rand/2/bin: de_rand_2_bin()\nDE/rand/2/bin with radius limited sampling (a type of trivial geography): BBO_de_rand_2_bin_radiuslimited()\nDirect search:\nGenerating set search:\nCompass/coordinate search: BBO_generating_set_search()\nDirect search through probabilistic descent: BBO_probabilistic_descent()\nResampling Memetic Searchers:\nResampling Memetic Search (RS): BBO_resampling_memetic_search()\nResampling Inheritance Memetic Search (RIS): BBO_resampling_inheritance_memetic_search()\nStochastic Approximation:\nSimultaneous Perturbation Stochastic Approximation (SPSA): BBO_simultaneous_perturbation_stochastic_approximation()\nRandomSearch (to compare to): BBO_random_search()","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The recommended optimizer is BBO_adaptive_de_rand_1_bin_radiuslimited()","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The currently available algorithms are listed here","category":"page"},{"location":"optimization_packages/blackboxoptim/#Example","page":"BlackBoxOptim.jl","title":"Example","text":"","category":"section"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The Rosenbrock function can be optimized using the BBO_adaptive_de_rand_1_bin_radiuslimited() as follows:","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"using Optimization, OptimizationBBO\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, BBO_adaptive_de_rand_1_bin_radiuslimited(), maxiters=100000, maxtime=1000.0)","category":"page"},{"location":"optimization_packages/nlopt/#NLopt.jl","page":"NLopt.jl","title":"NLopt.jl","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt is Julia package interfacing to the free/open-source NLopt library which implements many optimization methods both global and local NLopt Documentation.","category":"page"},{"location":"optimization_packages/nlopt/#Installation:-OptimizationNLopt.jl","page":"NLopt.jl","title":"Installation: OptimizationNLopt.jl","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"To use this package, install the OptimizationNLopt package:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"import Pkg; Pkg.add(\"OptimizationNLopt\")","category":"page"},{"location":"optimization_packages/nlopt/#Methods","page":"NLopt.jl","title":"Methods","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.jl algorithms are chosen either via NLopt.Opt(:algname, nstates) where nstates is the number of states to be optimized, but preferably via NLopt.AlgorithmName() where `AlgorithmName can be one of the following:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.GN_DIRECT()\nNLopt.GN_DIRECT_L()\nNLopt.GN_DIRECT_L_RAND()\nNLopt.GN_DIRECT_NOSCAL()\nNLopt.GN_DIRECT_L_NOSCAL()\nNLopt.GN_DIRECT_L_RAND_NOSCAL()\nNLopt.GN_ORIG_DIRECT()\nNLopt.GN_ORIG_DIRECT_L()\nNLopt.GD_STOGO()\nNLopt.GD_STOGO_RAND()\nNLopt.LD_LBFGS_NOCEDAL()\nNLopt.LD_LBFGS()\nNLopt.LN_PRAXIS()\nNLopt.LD_VAR1()\nNLopt.LD_VAR2()\nNLopt.LD_TNEWTON()\nNLopt.LD_TNEWTON_RESTART()\nNLopt.LD_TNEWTON_PRECOND()\nNLopt.LD_TNEWTON_PRECOND_RESTART()\nNLopt.GN_CRS2_LM()\nNLopt.GN_MLSL()\nNLopt.GD_MLSL()\nNLopt.GN_MLSL_LDS()\nNLopt.GD_MLSL_LDS()\nNLopt.LD_MMA()\nNLopt.LN_COBYLA()\nNLopt.LN_NEWUOA()\nNLopt.LN_NEWUOA_BOUND()\nNLopt.LN_NELDERMEAD()\nNLopt.LN_SBPLX()\nNLopt.LN_AUGLAG()\nNLopt.LD_AUGLAG()\nNLopt.LN_AUGLAG_EQ()\nNLopt.LD_AUGLAG_EQ()\nNLopt.LN_BOBYQA()\nNLopt.GN_ISRES()\nNLopt.AUGLAG()\nNLopt.AUGLAG_EQ()\nNLopt.G_MLSL()\nNLopt.G_MLSL_LDS()\nNLopt.LD_SLSQP()\nNLopt.LD_CCSAQ()\nNLopt.GN_ESCH()\nNLopt.GN_AGS()","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"See the NLopt Documentation for more details on each optimizer.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"Beyond the common arguments, the following optimizer parameters can be set as kwargs:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"stopval\nxtol_rel\nxtol_abs\nconstrtol_abs\ninitial_step\npopulation\nvector_storage","category":"page"},{"location":"optimization_packages/nlopt/#Local-Optimizer","page":"NLopt.jl","title":"Local Optimizer","text":"","category":"section"},{"location":"optimization_packages/nlopt/#Derivative-Free","page":"NLopt.jl","title":"Derivative-Free","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"Derivative-free optimizers are optimizers that can be used even in cases where no derivatives or automatic differentiation is specified. While they tend to be less efficient than derivative-based optimizers, they can be easily applied to cases where defining derivatives is difficult. Note that while these methods do not support general constraints, all support bounds constraints via lb and ub in the OptimizationProblem.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt derivative-free optimizers are:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.LN_PRAXIS()\nNLopt.LN_COBYLA()\nNLopt.LN_NEWUOA()\nNLopt.LN_NEWUOA_BOUND()\nNLopt.LN_NELDERMEAD()\nNLopt.LN_SBPLX()\nNLopt.LN_AUGLAG()\nNLopt.LN_AUGLAG_EQ()\nNLopt.LN_BOBYQA()","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The Rosenbrock function can be optimized using the NLopt.LN_NELDERMEAD() as follows:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"using Optimization\nusing OptimizationNLopt\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, NLopt.LN_NELDERMEAD())","category":"page"},{"location":"optimization_packages/nlopt/#Gradient-Based","page":"NLopt.jl","title":"Gradient-Based","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"Gradient-based optimizers are optimizers which utilize the gradient information based on derivatives defined or automatic differentiation.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt gradient-based optimizers are:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.LD_LBFGS_NOCEDAL()\nNLopt.LD_LBFGS()\nNLopt.LD_VAR1()\nNLopt.LD_VAR2()\nNLopt.LD_TNEWTON()\nNLopt.LD_TNEWTON_RESTART()\nNLopt.LD_TNEWTON_PRECOND()\nNLopt.LD_TNEWTON_PRECOND_RESTART()\nNLopt.LD_MMA()\nNLopt.LD_AUGLAG()\nNLopt.LD_AUGLAG_EQ()\nNLopt.LD_SLSQP()\nNLopt.LD_CCSAQ()","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The Rosenbrock function can be optimized using NLopt.LD_LBFGS() as follows:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"using Optimization, OptimizationNLopt\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, NLopt.LD_LBFGS())","category":"page"},{"location":"optimization_packages/nlopt/#Global-Optimizer","page":"NLopt.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/nlopt/#Without-Constraint-Equations","page":"NLopt.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The following algorithms in NLopt are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt global optimizers which fall into this category are:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.GN_DIRECT()\nNLopt.GN_DIRECT_L()\nNLopt.GN_DIRECT_L_RAND()\nNLopt.GN_DIRECT_NOSCAL()\nNLopt.GN_DIRECT_L_NOSCAL()\nNLopt.GN_DIRECT_L_RAND_NOSCAL()\nNLopt.GD_STOGO()\nNLopt.GD_STOGO_RAND()\nNLopt.GN_CRS2_LM()\nNLopt.GN_MLSL()\nNLopt.GD_MLSL()\nNLopt.GN_MLSL_LDS()\nNLopt.GD_MLSL_LDS()\nNLopt.G_MLSL()\nNLopt.G_MLSL_LDS()\nNLopt.GN_ESCH()","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The Rosenbrock function can be optimized using NLopt.GN_DIRECT() as follows:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"using Optimization, OptimizationNLopt\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, NLopt.GN_DIRECT(),maxtime=10.0)","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"Algorithms such as NLopt.G_MLSL() or NLopt.G_MLSL_LDS() also require a local optimizer to be selected, which via the local_method argument of solve.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The Rosenbrock function can be optimized using NLopt.G_MLSL_LDS() with NLopt.LN_NELDERMEAD() as the local optimizer. The local optimizer maximum iterations are set via local_maxiters:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"using Optimization, OptimizationNLopt\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, NLopt.G_MLSL_LDS(), local_method = NLopt.LD_LBFGS(),maxtime=10.0, local_maxiters=10)","category":"page"},{"location":"optimization_packages/nlopt/#With-Constraint-Equations","page":"NLopt.jl","title":"With Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The following algorithms in NLopt are performing global optimization on problems with constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"note: Constraints with NLopt\nEquality and inequality equation support for NLopt via Optimization is not supported directly. However, you can use the MOI wrapper to use constraints with NLopt optimizers.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt global optimizers which fall into this category are:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.GN_ORIG_DIRECT()\nNLopt.GN_ORIG_DIRECT_L()\nNLopt.GN_ISRES()\nNLopt.GN_AGS()","category":"page"},{"location":"API/solve/#Common-Solver-Options-(Solve-Keyword-Arguments)","page":"Common Solver Options (Solve Keyword Arguments)","title":"Common Solver Options (Solve Keyword Arguments)","text":"","category":"section"},{"location":"API/solve/","page":"Common Solver Options (Solve Keyword Arguments)","title":"Common Solver Options (Solve Keyword Arguments)","text":"solve(::OptimizationProblem,::Any)","category":"page"},{"location":"API/solve/#CommonSolve.solve-Tuple{OptimizationProblem, Any}","page":"Common Solver Options (Solve Keyword Arguments)","title":"CommonSolve.solve","text":"solve(prob::OptimizationProblem, alg::AbstractOptimizationAlgorithm, args...; kwargs...)\n\nKeyword Arguments\n\nThe arguments to solve are common across all of the optimizers. These common arguments are:\n\nmaxiters (the maximum number of iterations)\nmaxtime (the maximum of time the optimization runs for)\nabstol (absolute tolerance in changes of the objective value)\nreltol (relative tolerance  in changes of the objective value)\ncallback (a callback function)\n\nIf the chosen global optimzer employs a local optimization method a similar set of common local optimizer arguments exists. The common local optimizer arguments are:\n\nlocal_method (optimiser used for local optimization in global method)\nlocal_maxiters (the maximum number of iterations)\nlocal_maxtime (the maximum of time the optimization runs for)\nlocal_abstol (absolute tolerance in changes of the objective value)\nlocal_reltol (relative tolerance  in changes of the objective value)\nlocal_options (NamedTuple of keyword arguments for local optimizer)\n\nSome optimizer algorithms have special keyword arguments documented in the solver portion of the documentation and their respective documentation. These arguments can be passed as kwargs... to solve. Similarly, the special keyword arguments for the local_method of a global optimizer are passed as a NamedTuple to local_options.\n\nOver time we hope to cover more of these keyword arguments under the common interface.\n\nIf a common argument is not implemented for a optimizer a warning will be shown.\n\nCallback Functions\n\nThe callback function callback is a function which is called after every optimizer step. Its signature is:\n\ncallback = (x,other_args) -> false\n\nwhere other_args is are the extra return arguments of the optimization f. This allows for saving values from the optimization and using them for plotting and display without recalculating. The callback should return a Boolean value, and the default should be false, such that the optimization gets stopped if it returns true.\n\nCallback Example\n\nfunction loss(p)\n    # Some calculations\n    lossval,x,y,z\nend\n\nfunction callback(p,lossval,x,y,z)\n    # Do some analysis\n\n    # When lossval < 0.01, stop the optimization\n    lossval < 0.01\nend\n\n\n\n\n\n","category":"method"},{"location":"optimization_packages/metaheuristics/#Metaheuristics.jl","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Metaheuristics is a Julia package implementing metaheuristic algorithms for global optimization that does not require for the optimized function to be differentiable.","category":"page"},{"location":"optimization_packages/metaheuristics/#Installation:-OptimizationMetaheuristics.jl","page":"Metaheuristics.jl","title":"Installation: OptimizationMetaheuristics.jl","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"To use this package, install the OptimizationMetaheuristics package:","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"import Pkg; Pkg.add(\"OptimizationMetaheuristics\")","category":"page"},{"location":"optimization_packages/metaheuristics/#Global-Optimizer","page":"Metaheuristics.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/#Without-Constraint-Equations","page":"Metaheuristics.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"A Metaheuristics Single-Objective algorithm is called using one of the following:","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Evolutionary Centers Algorithm: ECA()\nDifferential Evolution: DE() with 5 different strategies\nDE(strategy=:rand1) - default strategy\nDE(strategy=:rand2)\nDE(strategy=:best1)\nDE(strategy=:best2)\nDE(strategy=:randToBest1)\nParticle Swarm Optimization: PSO()\nArtificial Bee Colony: ABC()\nGravitational Search Algorithm: CGSA()\nSimulated Annealing: SA()\nWhale Optimization Algorithm: WOA()","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Metaheuristics also performs Multiobjective optimization, but this is not yet supported by Optimization.","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Each optimizer sets default settings based on the optimization problem, but specific parameters can be set as shown in the original Documentation ","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Additionally, Metaheuristics common settings which would be defined by Metaheuristics.Options can be simply passed as special keyword arguments to solve without the need to use the Metaheuristics.Options struct.","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Lastly, information about the optimization problem such as the true optimum is set via Metaheuristics.Information and passed as part of the optimizer struct to solve e.g., solve(prob, ECA(information=Metaheuristics.Inoformation(f_optimum = 0.0)))","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"The currently available algorithms and their parameters are listed here.","category":"page"},{"location":"optimization_packages/metaheuristics/#Notes","page":"Metaheuristics.jl","title":"Notes","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"The algorithms in Metaheuristics are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/metaheuristics/#Examples","page":"Metaheuristics.jl","title":"Examples","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"The Rosenbrock function can be optimized using the Evolutionary Centers Algorithm ECA() as follows:","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"using Optimization, OptimizationMetaheuristics\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, ECA(), maxiters=100000, maxtime=1000.0)","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Per default Metaheuristics ignores the initial values x0 set in the OptimizationProblem. In order to for Optimization to use x0 we have to set use_initial=true:","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"sol = solve(prob, ECA(), use_initial=true, maxiters=100000, maxtime=1000.0)","category":"page"},{"location":"optimization_packages/metaheuristics/#With-Constraint-Equations","page":"Metaheuristics.jl","title":"With Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"While Metaheuristics.jl supports such constraints, Optimization.jl currently does not relay these constraints.","category":"page"},{"location":"optimization_packages/optim/#optim","page":"Optim.jl","title":"Optim.jl","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim is Julia package implementing various algorithms to perform univariate and multivariate optimization.","category":"page"},{"location":"optimization_packages/optim/#Installation:-OptimizationOptimJL.jl","page":"Optim.jl","title":"Installation: OptimizationOptimJL.jl","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"To use this package, install the OptimizationOptimJL package:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"import Pkg; Pkg.add(\"OptimizationOptimJL\")","category":"page"},{"location":"optimization_packages/optim/#Methods","page":"Optim.jl","title":"Methods","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl algorithms can be one of the following:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.NelderMead()\nOptim.SimulatedAnnealing()\nOptim.ParticleSwarm()\nOptim.ConjugateGradient()\nOptim.GradientDescent()\nOptim.BFGS()\nOptim.LBFGS()\nOptim.NGMRES()\nOptim.OACCEL()\nOptim.NewtonTrustRegion()\nOptim.Newton()\nOptim.KrylovTrustRegion()\nOptim.ParticleSwarm()\nOptim.SAMIN()","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Each optimizer also takes special arguments which are outlined in the sections below.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The following special keyword arguments which are not covered by the common solve arguments can be used with Optim.jl optimizers:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"x_tol: Absolute tolerance in changes of the input vector x, in infinity norm. Defaults to 0.0.\ng_tol: Absolute tolerance in the gradient, in infinity norm. Defaults to 1e-8. For gradient free methods, this will control the main convergence tolerance, which is solver-specific.\nf_calls_limit: A soft upper limit on the number of objective calls. Defaults to 0 (unlimited).\ng_calls_limit: A soft upper limit on the number of gradient calls. Defaults to 0 (unlimited).\nh_calls_limit: A soft upper limit on the number of Hessian calls. Defaults to 0 (unlimited).\nallow_f_increases: Allow steps that increase the objective value. Defaults to false. Note that, when setting this to true, the last iterate will be returned as the minimizer even if the objective increased.\nstore_trace: Should a trace of the optimization algorithm's state be stored? Defaults to false.\nshow_trace: Should a trace of the optimization algorithm's state be shown on stdout? Defaults to false.\nextended_trace: Save additional information. Solver dependent. Defaults to false.\ntrace_simplex: Include the full simplex in the trace for NelderMead. Defaults to false.\nshow_every: Trace output is printed every show_everyth iteration.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"For a more extensive documentation of all the algorithms and options, please consult the Documentation","category":"page"},{"location":"optimization_packages/optim/#Local-Optimizer","page":"Optim.jl","title":"Local Optimizer","text":"","category":"section"},{"location":"optimization_packages/optim/#Local-Constraint","page":"Optim.jl","title":"Local Constraint","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following local constraint algorithms:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.IPNewton()\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nμ0 specifies the initial barrier penalty coefficient as either a number or :auto\nshow_linesearch is an option to turn on linesearch verbosity.\nDefaults:\nlinesearch::Function = Optim.backtrack_constrained_grad\nμ0::Union{Symbol,Number} = :auto\nshow_linesearch::Bool = false","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function with constraints can be optimized using the Optim.IPNewton() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"using Optimization, OptimizationOptimJL\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\ncons= (res,x,p) -> res .= [x[1]^2 + x[2]^2]\nx0 = zeros(2)\np  = [1.0,100.0]\nprob = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff();cons= cons)\nprob = Optimization.OptimizationProblem(prob, x0, p, lcons = [-5.0], ucons = [10.0])\nsol = solve(prob, IPNewton())","category":"page"},{"location":"optimization_packages/optim/#Derivative-Free","page":"Optim.jl","title":"Derivative-Free","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Derivative-free optimizers are optimizers that can be used even in cases where no derivatives or automatic differentiation is specified. While they tend to be less efficient than derivative-based optimizers, they can be easily applied to cases where defining derivatives is difficult. Note that while these methods do not support general constraints, all support bounds constraints via lb and ub in the Optimization.OptimizationProblem.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following derivative-free algorithms:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.NelderMead(): Nelder-Mead optimizer\nsolve(problem, NelderMead(parameters, initial_simplex))\nparameters = AdaptiveParameters() or parameters = FixedParameters()\ninitial_simplex = AffineSimplexer()\nDefaults:\nparameters = AdaptiveParameters()\ninitial_simplex = AffineSimplexer()\nOptim.SimulatedAnnealing(): Simulated Annealing\nsolve(problem, SimulatedAnnealing(neighbor, T, p))\nneighbor is a mutating function of the current and proposed x\nT is a function of the current iteration that returns a temperature\np is a function of the current temperature\nDefaults:\nneighbor = default_neighbor!\nT = default_temperature\np = kirkpatrick\nOptim.ParticleSwarm()","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can be optimized using the Optim.NelderMead() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"using Optimization, OptimizationOptimJL\nrosenbrock(x, p) =  (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0,100.0]\nprob = Optimization.OptimizationProblem(rosenbrock, x0, p)\nsol = solve(prob, Optim.NelderMead())","category":"page"},{"location":"optimization_packages/optim/#Gradient-Based","page":"Optim.jl","title":"Gradient-Based","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Gradient-based optimizers are optimizers which utilize the gradient information based on derivatives defined or automatic differentiation.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following gradient-based algorithms:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.ConjugateGradient(): Conjugate Gradient Descent\nsolve(problem, ConjugateGradient(alphaguess, linesearch, eta, P, precondprep))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\neta determines the next step direction\nP is an optional preconditioner (for more information, see this source)\nprecondpred is used to update P as the state variable x changes\nDefaults:\nalphaguess = LineSearches.InitialHagerZhang()\nlinesearch = LineSearches.HagerZhang()\neta = 0.4\nP = nothing\nprecondprep = (P, x) -> nothing\nOptim.GradientDescent(): Gradient Descent (a quasi-Newton solver)\nsolve(problem, GradientDescent(alphaguess, linesearch, P, precondprep))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nP is an optional preconditioner (for more information, see this source)\nprecondpred is used to update P as the state variable x changes\nDefaults:\nalphaguess = LineSearches.InitialPrevious()\nlinesearch = LineSearches.HagerZhang()\nP = nothing\nprecondprep = (P, x) -> nothing\nOptim.BFGS(): Broyden-Fletcher-Goldfarb-Shanno algorithm\nsolve(problem, BFGS(alpaguess, linesearch, initial_invH, initial_stepnorm, manifold))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\ninitial_invH specifies an optional initial matrix\ninitial_stepnorm determines that initial_invH is an identity matrix scaled by the value of initial_stepnorm multiplied by the sup-norm of the gradient at the initial point\nmanifold specifies a (Riemannian) manifold on which the function is to be minimized (for more information, consult this source)\navailable manifolds:\nFlat\nSphere\nStiefel\nmeta-manifolds:\nPowerManifold\nProductManifold\ncustom manifolds\nDefaults:\nalphaguess = LineSearches.InitialStatic()\nlinesearch = LineSearches.HagerZhang()\ninitial_invH = nothing\ninitial_stepnorm = nothing\nmanifold = Flat()\nOptim.LBFGS(): Limited-memory Broyden-Fletcher-Goldfarb-Shanno algorithm\nm is the number of history points\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nP is an optional preconditioner (for more information, see this source)\nprecondpred is used to update P as the state variable x changes\nmanifold specifies a (Riemannian) manifold on which the function is to be minimized (for more information, consult this source)\navailable manifolds:\nFlat\nSphere\nStiefel\nmeta-manifolds:\nPowerManifold\nProductManifold\ncustom manifolds\nscaleinvH0: whether to scale the initial Hessian approximation\nDefaults:\nm = 10\nalphaguess = LineSearches.InitialStatic()\nlinesearch = LineSearches.HagerZhang()\nP = nothing\nprecondprep = (P, x) -> nothing\nmanifold = Flat()\nscaleinvH0::Bool = true && (typeof(P) <: Nothing)\nOptim.NGMRES()\nOptim.OACCEL()","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can be optimized using the Optim.LBFGS() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"using Optimization, OptimizationOptimJL\nrosenbrock(x, p) =  (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0,100.0]\noptprob = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(optprob, x0, p, lb=[-1.0, -1.0], ub=[0.8, 0.8])\nsol = solve(prob, Optim.LBFGS())","category":"page"},{"location":"optimization_packages/optim/#Hessian-Based-Second-Order","page":"Optim.jl","title":"Hessian-Based Second Order","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Hessian-based optimization methods are second order optimization methods which use the direct computation of the Hessian. These can converge faster, but require fast and accurate methods for calculating the Hessian in order to be appropriate.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following hessian-based algorithms:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.NewtonTrustRegion(): Newton Trust Region method\ninitial_delta: The starting trust region radius\ndelta_hat: The largest allowable trust region radius\neta: When rho is at least eta, accept the step.\nrho_lower: When rho is less than rho_lower, shrink the trust region.\nrho_upper: When rho is greater than rhoupper, grow the trust region (though no greater than deltahat).\nDefaults:\ninitial_delta = 1.0\ndelta_hat = 100.0\neta = 0.1\nrho_lower = 0.25\nrho_upper = 0.75\nOptim.Newton(): Newton's method with line search\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nDefaults:\nalphaguess = LineSearches.InitialStatic()\nlinesearch = LineSearches.HagerZhang()","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can be optimized using the Optim.Newton() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"using Optimization, OptimizationOptimJL, ModelingToolkit\nrosenbrock(x, p) =  (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0,100.0]\nf = OptimizationFunction(rosenbrock,Optimization.AutoModelingToolkit())\nprob = Optimization.OptimizationProblem(f,x0,p)\nsol = solve(prob,Optim.Newton())","category":"page"},{"location":"optimization_packages/optim/#Hessian-Free-Second-Order","page":"Optim.jl","title":"Hessian-Free Second Order","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Hessian-free methods are methods which perform second order optimization by direct computation of Hessian-vector products (Hv) without requiring the construction of the full Hessian. As such, these methods can perform well for large second order optimization problems, but can require special case when considering conditioning of the Hessian.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following hessian-free algorithms:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.KrylovTrustRegion(): A Newton-Krylov method with Trust Regions\ninitial_delta: The starting trust region radius\ndelta_hat: The largest allowable trust region radius\neta: When rho is at least eta, accept the step.\nrho_lower: When rho is less than rho_lower, shrink the trust region.\nrho_upper: When rho is greater than rhoupper, grow the trust region (though no greater than deltahat).\nDefaults:\ninitial_delta = 1.0\ndelta_hat = 100.0\neta = 0.1\nrho_lower = 0.25\nrho_upper = 0.75","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can be optimized using the Optim.KrylovTrustRegion() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"using Optimization, OptimizationOptimJL\nrosenbrock(x, p) =  (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0,100.0]\noptprob = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(optprob, x0, p)\nsol = solve(prob, Optim.KrylovTrustRegion())","category":"page"},{"location":"optimization_packages/optim/#Global-Optimizer","page":"Optim.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/optim/#Without-Constraint-Equations","page":"Optim.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The following method in Optim performs global optimization on problems with or without box constraints. It works both with and without lower and upper bounds set by lb and ub in the Optimization.OptimizationProblem.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.ParticleSwarm(): Particle Swarm Optimization\nsolve(problem, ParticleSwarm(lower, upper, n_particles))\nlower/upper are vectors of lower/upper bounds respectively\nn_particles is the number of particles in the swarm\ndefaults to: lower = [], upper = [], n_particles = 0","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can be optimized using the Optim.ParticleSwarm() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"using Optimization, OptimizationOptimJL\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0,100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb=[-1.0, -1.0], ub=[1.0, 1.0])\nsol = solve(prob, Optim.ParticleSwarm(lower=prob.lb, upper= prob.ub, n_particles=100))","category":"page"},{"location":"optimization_packages/optim/#With-Constraint-Equations","page":"Optim.jl","title":"With Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The following method in Optim performs global optimization on problems with box constraints.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.SAMIN(): Simulated Annealing with bounds\nsolve(problem, SAMIN(nt, ns, rt, neps, f_tol, x_tol, coverage_ok, verbosity))\nDefaults:\nnt = 5\nns = 5\nrt = 0.9\nneps = 5\nf_tol = 1e-12\nx_tol = 1e-6\ncoverage_ok = false\nverbosity = 0","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can be optimized using the Optim.SAMIN() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"using Optimization, OptimizationOptimJL\nrosenbrock(x, p) =  (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0,100.0]\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(f, x0, p, lb=[-1.0, -1.0], ub=[1.0, 1.0])\nsol = solve(prob, Optim.SAMIN())","category":"page"},{"location":"tutorials/rosenbrock/#Solving-the-Rosenbrock-Problem-in-10-Ways","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"","category":"section"},{"location":"tutorials/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"This tutorial is a demonstration of many different solvers to demonstrate the flexibility of Optimization.jl. This is a gauntlet of many solvers to get a feel for common workflows of the package and give copy-pastable starting points.","category":"page"},{"location":"tutorials/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"note: Note\nThis example uses many different solvers of Optimization.jl. Each solver subpackage needs to be installed separate. For example, for the details on the installation and usage of OptimizationOptimJL.jl package, see the Optim.jl page.","category":"page"},{"location":"tutorials/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"# Define the problem to solve\nusing Optimization, ForwardDiff, Zygote\n\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p  = [1.0, 100.0]\n\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nl1 = rosenbrock(x0, _p)\nprob = OptimizationProblem(f, x0, _p)\n\n## Optim.jl Solvers\n\nusing OptimizationOptimJL\n\n# Start with some derivative-free optimizers\n\nsol = solve(prob, SimulatedAnnealing())\nprob = OptimizationProblem(f, x0, _p, lb=[-1.0, -1.0], ub=[0.8, 0.8])\nsol = solve(prob, SAMIN())\n\nl1 = rosenbrock(x0, _p)\nprob = OptimizationProblem(rosenbrock, x0, _p)\nsol = solve(prob, NelderMead())\n\n# Now a gradient-based optimizer with forward-mode automatic differentiation\n\noptf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = OptimizationProblem(optf, x0, _p)\nsol = solve(prob, BFGS())\n\n# Now a second order optimizer using Hessians generated by forward-mode automatic differentiation\n\nsol = solve(prob, Newton())\n\n# Now a second order Hessian-free optimizer\n\nsol = solve(prob, Optim.KrylovTrustRegion())\n\n# Now derivative-based optimizers with various constraints\n\ncons = (res,x,p) -> res .= [x[1]^2 + x[2]^2]\noptf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff();cons= cons)\n\nprob = OptimizationProblem(optf, x0, _p, lcons = [-Inf], ucons = [Inf])\nsol = solve(prob, IPNewton()) # Note that -Inf < x[1]^2 + x[2]^2 < Inf is always true\n\nprob = OptimizationProblem(optf, x0, _p, lcons = [-5.0], ucons = [10.0])\nsol = solve(prob, IPNewton()) # Again, -5.0 < x[1]^2 + x[2]^2 < 10.0\n\nprob = OptimizationProblem(optf, x0, _p, lcons = [-Inf], ucons = [Inf],\n                           lb = [-500.0,-500.0], ub=[50.0,50.0])\nsol = solve(prob, IPNewton())\n\nprob = OptimizationProblem(optf, x0, _p, lcons = [0.5], ucons = [0.5],\n                           lb = [-500.0,-500.0], ub=[50.0,50.0])\nsol = solve(prob, IPNewton()) # Notice now that x[1]^2 + x[2]^2 ≈ 0.5:\n                              # cons(sol.minimizer, _p) = 0.49999999999999994\n\nfunction con_c(res,x,p)\n    res .= [x[1]^2 + x[2]^2]\nend\n\noptf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff();cons= con_c)\nprob = OptimizationProblem(optf, x0, _p, lcons = [-Inf], ucons = [0.25^2])\nsol = solve(prob, IPNewton()) # -Inf < cons_circ(sol.minimizer, _p) = 0.25^2\n\nfunction con2_c(res,x,p)\n    res .= [x[1]^2 + x[2]^2, x[2]*sin(x[1])-x[1]]\nend\n\noptf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff();cons= con2_c)\nprob = OptimizationProblem(optf, x0, _p, lcons = [-Inf,-Inf], ucons = [Inf,Inf])\nsol = solve(prob, IPNewton())\n\n\n\n# Now let's switch over to OptimizationOptimisers with reverse-mode AD\n\nusing OptimizationOptimisers\noptf = OptimizationFunction(rosenbrock, Optimization.AutoZygote())\nprob = OptimizationProblem(optf, x0, _p)\nsol = solve(prob, Adam(0.05), maxiters = 1000, progress = false)\n\n## Try out CMAEvolutionStrategy.jl's evolutionary methods\n\nusing OptimizationCMAEvolutionStrategy\nsol = solve(prob, CMAEvolutionStrategyOpt())\n\n## Now try a few NLopt.jl solvers with symbolic differentiation via ModelingToolkit.jl\n\nusing OptimizationNLopt, ModelingToolkit\noptf = OptimizationFunction(rosenbrock, Optimization.AutoModelingToolkit())\nprob = OptimizationProblem(optf, x0, _p)\n\nsol = solve(prob, Opt(:LN_BOBYQA, 2))\nsol = solve(prob, Opt(:LD_LBFGS, 2))\n\n## Add some box constraints and solve with a few NLopt.jl methods\n\nprob = OptimizationProblem(optf, x0, _p, lb=[-1.0, -1.0], ub=[0.8, 0.8])\nsol = solve(prob, Opt(:LD_LBFGS, 2))\n# sol = solve(prob, Opt(:G_MLSL_LDS, 2), nstart=2, local_method = Opt(:LD_LBFGS, 2), maxiters=10000)\n\n## Evolutionary.jl Solvers\n\nusing OptimizationEvolutionary\nsol = solve(prob, CMAES(μ =40 , λ = 100),abstol=1e-15) # -1.0 ≤ x[1], x[2] ≤ 0.8\n\n## BlackBoxOptim.jl Solvers\n\nusing OptimizationBBO\nprob = Optimization.OptimizationProblem(rosenbrock, x0, _p, lb=[-1.0, 0.2], ub=[0.8, 0.43])\nsol = solve(prob, BBO_adaptive_de_rand_1_bin()) # -1.0 ≤ x[1] ≤ 0.8, 0.2 ≤ x[2] ≤ 0.43","category":"page"},{"location":"tutorials/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"And this is only a small subset of what Optimization.jl has to offer!","category":"page"},{"location":"optimization_packages/mathoptinterface/#MathOptInterface.jl","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"MathOptInterface is a Julia abstraction layer to interface with a variety of mathematical optimization solvers.","category":"page"},{"location":"optimization_packages/mathoptinterface/#Installation:-OptimizationMOI.jl","page":"MathOptInterface.jl","title":"Installation: OptimizationMOI.jl","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"To use this package, install the OptimizationMOI package:","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"import Pkg; Pkg.add(\"OptimizationMOI\")","category":"page"},{"location":"optimization_packages/mathoptinterface/#Details","page":"MathOptInterface.jl","title":"Details","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"As of now, the Optimization interface to MathOptInterface implements only the maxtime common keyword argument. ","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"An optimizer which supports the MathOptInterface API can be called directly if no optimizer options have to be defined. ","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"For example, using the Ipopt.jl optimizer:","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"using OptimizationMOI, Ipopt\nsol = solve(prob, Ipopt.Optimizer())","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"The optimizer options are handled in one of two ways. They can either be set via OptimizationMOI.MOI.OptimizerWithAttributes() or as keyword arguments to solve. ","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"For example, using the Ipopt.jl optimizer:","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"using OptimizationMOI, Ipopt\nopt = OptimizationMOI.MOI.OptimizerWithAttributes(Ipopt.Optimizer, \"option_name\" => option_value, ...)\nsol = solve(prob, opt)\n\nsol = solve(prob,  Ipopt.Optimizer(); option_name = option_value, ...)","category":"page"},{"location":"optimization_packages/mathoptinterface/#Optimizers","page":"MathOptInterface.jl","title":"Optimizers","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/#Ipopt.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"Ipopt.jl (MathOptInterface)","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"Ipopt.Optimizer\nThe full list of optimizer options can be found in the Ipopt Documentation","category":"page"},{"location":"optimization_packages/mathoptinterface/#KNITRO.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"KNITRO.jl (MathOptInterface)","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"KNITRO.Optimizer\nThe full list of optimizer options can be found in the KNITRO Documentation","category":"page"},{"location":"optimization_packages/mathoptinterface/#Juniper.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"Juniper.jl (MathOptInterface)","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"Juniper.Optimizer\nJuniper requires a nonlinear optimizer to be set via the nl_solver option, which must be a MathOptInterface-based optimizer. See the Juniper documentation for more detail.","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"using Optimization, OptimizationMOI, Juniper, Ipopt\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p  = [1.0, 100.0]\n\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(f, x0, _p)\n\nopt = OptimizationMOI.MOI.OptimizerWithAttributes(\n    Juniper.Optimizer,\n    \"nl_solver\"=>OptimizationMOI.MOI.OptimizerWithAttributes(Ipopt.Optimizer, \"print_level\"=>0),\n)\nsol = solve(prob, opt)","category":"page"},{"location":"tutorials/minibatch/#Data-Iterators-and-Minibatching","page":"Data Iterators and Minibatching","title":"Data Iterators and Minibatching","text":"","category":"section"},{"location":"tutorials/minibatch/","page":"Data Iterators and Minibatching","title":"Data Iterators and Minibatching","text":"It is possible to solve an optimization problem with batches using a Flux.Data.DataLoader, which is passed to Optimization.solve with ncycles. All data for the batches need to be passed as a tuple of vectors.","category":"page"},{"location":"tutorials/minibatch/","page":"Data Iterators and Minibatching","title":"Data Iterators and Minibatching","text":"note: Note\nThis example uses the OptimizationOptimisers.jl package. See the  Optimisers.jl page for details on the installation and usage.","category":"page"},{"location":"tutorials/minibatch/","page":"Data Iterators and Minibatching","title":"Data Iterators and Minibatching","text":"using Flux, Optimization, OptimizationOptimisers, OrdinaryDiffEq, SciMLSensitivity\n\nfunction newtons_cooling(du, u, p, t)\n    temp = u[1]\n    k, temp_m = p\n    du[1] = dT = -k*(temp-temp_m)\nend\n\nfunction true_sol(du, u, p, t)\n    true_p = [log(2)/8.0, 100.0]\n    newtons_cooling(du, u, true_p, t)\nend\n\nann = Chain(Dense(1,8,tanh), Dense(8,1,tanh))\npp,re = Flux.destructure(ann)\n\nfunction dudt_(u,p,t)\n    re(p)(u) .* u\nend\n\ncallback = function (p,l,pred;doplot=false) #callback function to observe training\n    display(l)\n    # plot current prediction against data\n    if doplot\n      pl = scatter(t,ode_data[1,:],label=\"data\")\n      scatter!(pl,t,pred[1,:],label=\"prediction\")\n      display(plot(pl))\n    end\n    return false\nend\n\nu0 = Float32[200.0]\ndatasize = 30\ntspan = (0.0f0, 1.5f0)\n\nt = range(tspan[1], tspan[2], length=datasize)\ntrue_prob = ODEProblem(true_sol, u0, tspan)\node_data = Array(solve(true_prob, Tsit5(), saveat=t))\n\nprob = ODEProblem{false}(dudt_, u0, tspan, pp)\n\nfunction predict_adjoint(fullp, time_batch)\n    Array(solve(prob, Tsit5(), p = fullp, saveat = time_batch))\nend\n\nfunction loss_adjoint(fullp, batch, time_batch)\n    pred = predict_adjoint(fullp,time_batch)\n    sum(abs2, batch .- pred), pred\nend\n\n\nk = 10\n# Pass the data for the batches as separate vectors wrapped in a tuple\ntrain_loader = Flux.Data.DataLoader((ode_data, t), batchsize = k)\n\nnumEpochs = 300\nl1 = loss_adjoint(pp, train_loader.data[1], train_loader.data[2])[1]\n\noptfun = OptimizationFunction((θ, p, batch, time_batch) -> loss_adjoint(θ, batch, time_batch), Optimization.AutoZygote())\noptprob = OptimizationProblem(optfun, pp)\nusing IterTools: ncycle\nres1 = Optimization.solve(optprob, Optimisers.ADAM(0.05), ncycle(train_loader, numEpochs), callback = callback)","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/#CMAEvolutionStrategy.jl","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"CMAEvolutionStrategy is a Julia package implementing the Covariance Matrix Adaptation Evolution Strategy algorithm. ","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"The CMAEvolutionStrategy algorithm is called by CMAEvolutionStrategyOpt()","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/#Installation:-OptimizationCMAEvolutionStrategy.jl","page":"CMAEvolutionStrategy.jl","title":"Installation: OptimizationCMAEvolutionStrategy.jl","text":"","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"To use this package, install the OptimizationCMAEvolutionStrategy package:","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"import Pkg; Pkg.add(\"OptimizationCMAEvolutionStrategy\")","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/#Global-Optimizer","page":"CMAEvolutionStrategy.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/#Without-Constraint-Equations","page":"CMAEvolutionStrategy.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"The method in CMAEvolutionStrategy is performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/#Example","page":"CMAEvolutionStrategy.jl","title":"Example","text":"","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"The Rosenbrock function can be optimized using the CMAEvolutionStrategyOpt() as follows:","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"using Optimization, OptimizationCMAEvolutionStrategy\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, CMAEvolutionStrategyOpt())","category":"page"},{"location":"API/optimization_solution/#Optimization-Solutions","page":"Optimization Solutions","title":"Optimization Solutions","text":"","category":"section"},{"location":"API/optimization_solution/","page":"Optimization Solutions","title":"Optimization Solutions","text":"SciMLBase.OptimizationSolution","category":"page"},{"location":"API/optimization_solution/#SciMLBase.OptimizationSolution","page":"Optimization Solutions","title":"SciMLBase.OptimizationSolution","text":"struct OptimizationSolution{T, N, uType, C<:SciMLBase.AbstractOptimizationCache, A, OV, O, S} <: SciMLBase.AbstractOptimizationSolution{T, N}\n\nRepresentation of the solution to an non-linear optimization defined by an OptimizationProblem\n\nFields\n\nu: the representation of the optimization's solution.\ncache::AbstractOptimizationCache: the optimization cache` that was solved.\nalg: the algorithm type used by the solver.\nobjective: Objective value of the solution\nretcode: the return code from the solver. Used to determine whether the solver solved successfully or whether it exited due to an error. For more details, see  the return code documentation.\noriginal: if the solver is wrapped from an alternative solver ecosystem, such as Optim.jl, then this is the original return from said solver library.\nsolve_time: Solve time from the solver in Seconds\n\n\n\n\n\n","category":"type"},{"location":"optimization_packages/nonconvex/#Nonconvex.jl","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"","category":"section"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"Nonconvex is a Julia package implementing and wrapping nonconvex constrained optimization algorithms.","category":"page"},{"location":"optimization_packages/nonconvex/#Installation:-OptimizationNonconvex.jl","page":"Nonconvex.jl","title":"Installation: OptimizationNonconvex.jl","text":"","category":"section"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"To use this package, install the OptimizationNonconvex package:","category":"page"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"import Pkg; Pkg.add(\"OptimizationNonconvex\")","category":"page"},{"location":"optimization_packages/nonconvex/#Global-Optimizer","page":"Nonconvex.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/nonconvex/#Without-Constraint-Equations","page":"Nonconvex.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"A Nonconvex algorithm is called using one of the following:","category":"page"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"Method of moving asymptotes (MMA):\nMMA87()\nMMA02()\nIpopt:\nIpoptAlg()\nNLopt:\nNLoptAlg(solver) where solver can be any of the NLopt algorithms\nAugmented Lagrangian algorithm:\nAugLag()\nonly works with constraints\nMixed integer nonlinear programming (MINLP):\nJuniper + Ipopt: JuniperIpoptAlg()\nPavito + Ipopt + Cbc: PavitoIpoptCbcAlg()\nMulti-start optimization:\nHyperoptAlg(subsolver) where subalg can be any of the described Nonconvex algorithm\nSurrogate-assisted Bayesian optimization\nBayesOptAlg(subsolver) where subalg can be any of the described Nonconvex algorithm\nMultiple Trajectory Search\nMTSAlg()","category":"page"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"When performing optimizing a combination of integer and floating-point parameters, the integer keyword has to be set. It takes a boolean vector indicating which parameter is an integer.","category":"page"},{"location":"optimization_packages/nonconvex/#Notes","page":"Nonconvex.jl","title":"Notes","text":"","category":"section"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"Some optimizer may require further options to be defined in order to work.","category":"page"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"The currently available algorithms are listed here","category":"page"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"The algorithms in Nonconvex are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/nonconvex/#Examples","page":"Nonconvex.jl","title":"Examples","text":"","category":"section"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"The Rosenbrock function can be optimized using the Method of moving asymptotes algorithm MMA02() as follows:","category":"page"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, MMA02(), maxiters=100000, maxtime=1000.0)","category":"page"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"The options of for a sub-algorithm are passed simply as a NamedTuple and Optimization.jl infers the correct Nonconvex options struct:","category":"page"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, HyperoptAlg(IpoptAlg()), sub_options=(;max_iter=100))","category":"page"},{"location":"optimization_packages/nonconvex/#With-Constraint-Equations","page":"Nonconvex.jl","title":"With Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"While Nonconvex.jl supports such constraints, Optimization.jl currently does not relay these constraints.","category":"page"},{"location":"API/optimization_problem/#Defining-OptimizationProblems","page":"Defining OptimizationProblems","title":"Defining OptimizationProblems","text":"","category":"section"},{"location":"API/optimization_problem/","page":"Defining OptimizationProblems","title":"Defining OptimizationProblems","text":"SciMLBase.OptimizationProblem","category":"page"},{"location":"API/optimization_problem/#SciMLBase.OptimizationProblem","page":"Defining OptimizationProblems","title":"SciMLBase.OptimizationProblem","text":"Defines a optimization problem. Documentation Page: https://docs.sciml.ai/Optimization/stable/API/optimization_problem/\n\nMathematical Specification of a Optimization Problem\n\nTo define an Optimization Problem, you simply need to give the function f which defines the cost function to minimize:\n\nmin_u f(up)\n\nu₀ is an initial guess of the minimum. f should be specified as f(u,p) and u₀ should be an AbstractArray (or number) whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher-dimension tensors as well.\n\nProblem Type\n\nConstructors\n\nOptimizationProblem{iip}(f, x, p = SciMLBase.NullParameters(),;\n                        lb = nothing,\n                        ub = nothing,\n                        lcons = nothing,\n                        ucons = nothing,\n                        sense = nothing,\n                        kwargs...)\n\nisinplace optionally sets whether the function is in-place or not. This is determined automatically, but not inferred. Note that for OptimizationProblem, in-place only refers to the Jacobian and Hessian functions, and thus by default if the OptimizationFunction is not defined directly then iip = true is done by default.\n\nParameters are optional, and if not given, then a NullParameters() singleton will be used, which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nlb and ub are the upper and lower bounds for box constraints on the optimization. They should be an AbstractArray matching the geometry of u, where (lb[I],ub[I]) is the box constraint (lower and upper bounds) for u[I].\n\nlcons and ucons are the upper and lower bounds for equality constraints on the optimization. They should be an AbstractArray matching the geometry of u, where (lcons[I],ucons[I]) is the constraint (lower and upper bounds) for cons[I].\n\nIf f is a standard Julia function, it is automatically transformed into an  OptimizationFunction with NoAD(), meaning the derivative functions are not  automatically generated.\n\nAny extra keyword arguments are captured to be sent to the optimizers.\n\nFields\n\nf: the function in the problem.\nu0: the initial guess for the optima.\np: the parameters for the problem. Defaults to NullParameters.\nlb: the lower bounds for the optimization of u.\nub: the upper bounds for the optimization of u.\nint: integrality indicator for u.\nlcons: the vector of lower bounds for the constraints passed to OptimizationFunction.   Defaults to nothing, implying no lower bounds for the constraints (i.e. the constraint bound is -Inf)\nucons: the vector of upper bounds for the constraints passed to OptimizationFunction.   Defaults to nothing, implying no upper bounds for the constraints (i.e. the constraint bound is Inf)\nsense: the objective sense, can take MaxSense or MinSense from Optimization.jl.\nkwargs: the keyword arguments passed on to the solvers.\n\nInequality and Equality Constraints\n\nBoth inequality and equality constraints are defined by the f.cons function in the OptimizationFunction description of the problem structure. This f.cons is given as a function f.cons(u,p) which computes the value of the constraints at u. For example, take f.cons(u,p) = u[1] - u[2]. With these definitions, lcons and ucons define the bounds on the constraint that the solvers try to satisfy. If lcons and ucons are nothing, then there are no constraints bounds, meaning that the constraint is satisfied when -Inf < f.cons < Inf (which of course is always!). If lcons[i] = ucons[i] = 0, then the constraint is satisfied when f.cons(u,p)[i] = 0, and so this implies the equality constraint u[1] = u[2]. If lcons[i] = ucons[i] = a, then u1 - u2 = a is the equality constraint.\n\nInequality constraints are then given by making lcons[i] != ucons[i]. For example, lcons[i] = -Inf and ucons[i] = 0 would imply the inequality constraint u1 = u2 since any f.cons[i] <= 0 satisfies the constraint. Similarly, lcons[i] = -1 and ucons[i] = 1 would imply that -1 <= f.cons[i] <= 1 is required or -1 = u1 - u2 = 1.\n\nNote that these vectors must be sized to match the number of constraints, with one set of conditions for each constraint.\n\n\n\n","category":"type"},{"location":"optimization_packages/speedmapping/#SpeedMapping.jl","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"","category":"section"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"SpeedMapping accelerates the convergence of a mapping to a fixed point by the Alternating cyclic extrapolation algorithm which can also perform multivariate optimization based on the gradient function.","category":"page"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"The SpeedMapping algorithm is called by SpeedMappingOpt()","category":"page"},{"location":"optimization_packages/speedmapping/#Installation:-OptimizationSpeedMapping.jl","page":"SpeedMapping.jl","title":"Installation: OptimizationSpeedMapping.jl","text":"","category":"section"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"To use this package, install the OptimizationSpeedMapping package:","category":"page"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"import Pkg; Pkg.add(\"OptimizationSpeedMapping\")","category":"page"},{"location":"optimization_packages/speedmapping/#Global-Optimizer","page":"SpeedMapping.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/speedmapping/#Without-Constraint-Equations","page":"SpeedMapping.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"The method in SpeedMapping is performing optimization on problems without constraint equations. Lower and upper constraints set by lb and ub in the OptimizationProblem are optional.","category":"page"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"If no AD backend is defined via OptimizationFunction the gradient is calculated via SpeedMapping's ForwardDiff AD backend.","category":"page"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"The Rosenbrock function can be optimized using the SpeedMappingOpt() with and without bound as follows:","category":"page"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"using Optimization, OptimizationSpeedMapping\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = OptimizationProblem(f, x0, p)\nsol = solve(prob,SpeedMappingOpt())\n\nprob = OptimizationProblem(f, x0, p;lb=[0.0,0.0], ub=[1.0,1.0])\nsol = solve(prob,SpeedMappingOpt())","category":"page"},{"location":"optimization_packages/flux/#Flux.jl","page":"Flux.jl","title":"Flux.jl","text":"","category":"section"},{"location":"optimization_packages/flux/#Installation:-OptimizationFlux.jl","page":"Flux.jl","title":"Installation: OptimizationFlux.jl","text":"","category":"section"},{"location":"optimization_packages/flux/","page":"Flux.jl","title":"Flux.jl","text":"To use this package, install the OptimizationFlux package:","category":"page"},{"location":"optimization_packages/flux/","page":"Flux.jl","title":"Flux.jl","text":"import Pkg; Pkg.add(\"OptimizationFlux\")","category":"page"},{"location":"optimization_packages/flux/","page":"Flux.jl","title":"Flux.jl","text":"warn: Warn\nFlux's optimizers are soon to be deprecated by Optimisers.jl Because of this, we recommend using the OptimizationOptimisers.jl setup instead of OptimizationFlux.jl","category":"page"},{"location":"optimization_packages/flux/#Local-Unconstrained-Optimizers","page":"Flux.jl","title":"Local Unconstrained Optimizers","text":"","category":"section"},{"location":"optimization_packages/flux/","page":"Flux.jl","title":"Flux.jl","text":"Flux.Optimise.Descent: Classic gradient descent optimizer with learning rate\nsolve(problem, Descent(η))\nη is the learning rate\nDefaults:\nη = 0.1\nFlux.Optimise.Momentum: Classic gradient descent optimizer with learning rate and momentum\nsolve(problem, Momentum(η, ρ))\nη is the learning rate\nρ is the momentum\nDefaults:\nη = 0.01\nρ = 0.9\nFlux.Optimise.Nesterov: Gradient descent optimizer with learning rate and Nesterov momentum\nsolve(problem, Nesterov(η, ρ))\nη is the learning rate\nρ is the Nesterov momentum\nDefaults:\nη = 0.01\nρ = 0.9\nFlux.Optimise.RMSProp: RMSProp optimizer\nsolve(problem, RMSProp(η, ρ))\nη is the learning rate\nρ is the momentum\nDefaults:\nη = 0.001\nρ = 0.9\nFlux.Optimise.ADAM: ADAM optimizer\nsolve(problem, ADAM(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nFlux.Optimise.RADAM: Rectified ADAM optimizer\nsolve(problem, RADAM(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nFlux.Optimise.AdaMax: AdaMax optimizer\nsolve(problem, AdaMax(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nFlux.Optimise.ADAGRad: ADAGrad optimizer\nsolve(problem, ADAGrad(η))\nη is the learning rate\nDefaults:\nη = 0.1\nFlux.Optimise.ADADelta: ADADelta optimizer\nsolve(problem, ADADelta(ρ))\nρ is the gradient decay factor\nDefaults:\nρ = 0.9\nFlux.Optimise.AMSGrad: AMSGrad optimizer\nsolve(problem, AMSGrad(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nFlux.Optimise.NADAM: Nesterov variant of the ADAM optimizer\nsolve(problem, NADAM(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nFlux.Optimise.ADAMW: ADAMW optimizer\nsolve(problem, ADAMW(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\ndecay is the decay to weights\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\ndecay = 0","category":"page"},{"location":"optimization_packages/nomad/#NOMAD.jl","page":"NOMAD.jl","title":"NOMAD.jl","text":"","category":"section"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"NOMAD is Julia package interfacing to NOMAD, which is a C++ implementation of the Mesh Adaptive Direct Search algorithm (MADS), designed for difficult blackbox optimization problems. These issues occur when the functions defining the objective and constraints are the result of costly computer simulations. NOMAD.jl documentation","category":"page"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"The NOMAD algorithm is called by NOMADOpt()","category":"page"},{"location":"optimization_packages/nomad/#Installation:-OptimizationNOMAD.jl","page":"NOMAD.jl","title":"Installation: OptimizationNOMAD.jl","text":"","category":"section"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"To use this package, install the OptimizationNOMAD package:","category":"page"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"import Pkg; Pkg.add(\"OptimizationNOMAD\")","category":"page"},{"location":"optimization_packages/nomad/#Global-Optimizer","page":"NOMAD.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/nomad/#Without-Constraint-Equations","page":"NOMAD.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"The method in NOMAD is performing global optimization on problems both with and without constraint equations. However, linear and nonlinear constraints defined in Optimization are currently not passed.","category":"page"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"NOMAD works both with and without lower and upper box-constraints set by lb and ub in the OptimizationProblem.","category":"page"},{"location":"optimization_packages/nomad/#Examples","page":"NOMAD.jl","title":"Examples","text":"","category":"section"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"The Rosenbrock function can be optimized using the NOMADOpt() with and without box-constraints as follows:","category":"page"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"using Optimization, OptimizationNOMAD\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\n\nprob = OptimizationProblem(f, x0, p)\nsol = Optimization.solve(prob,NOMADOpt())\n\nprob = OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.5,1.5])\nsol = Optimization.solve(prob,NOMADOpt())","category":"page"},{"location":"optimization_packages/multistartoptimization/#MultiStartOptimization.jl","page":"MultistartOptimization.jl","title":"MultiStartOptimization.jl","text":"","category":"section"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"MultistartOptimization is a Julia package implementing a global optimization multistart method which performs local optimization after choosing multiple starting points.","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"MultistartOptimization requires both a global and local method to be defined. The global multistart method chooses a set of initial starting points from where local the local method starts from.","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"Currently, only one global method (TikTak) is implemented and called by MultistartOptimization.TikTak(n) where n is the number of initial Sobol points. ","category":"page"},{"location":"optimization_packages/multistartoptimization/#Installation:-OptimizationMultistartOptimization.jl","page":"MultistartOptimization.jl","title":"Installation: OptimizationMultistartOptimization.jl","text":"","category":"section"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"To use this package, install the OptimizationMultistartOptimization package:","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"import Pkg; Pkg.add(\"OptimizationMultistartOptimization\")","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"note: Note\n","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"You also need to load the relevant subpackage for the local method of your choice, for example if you plan to use one of the NLopt.jl's optimizers, you'd install and load OptimizationNLopt as described in the NLopt.jl's section.","category":"page"},{"location":"optimization_packages/multistartoptimization/#Global-Optimizer","page":"MultistartOptimization.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/multistartoptimization/#Without-Constraint-Equations","page":"MultistartOptimization.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"The methods in MultistartOptimization are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/multistartoptimization/#Examples","page":"MultistartOptimization.jl","title":"Examples","text":"","category":"section"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"The Rosenbrock function can be optimized using MultistartOptimization.TikTak() with 100 initial points and the local method NLopt.LD_LBFGS() as follows:","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"using Optimization, OptimizationMultistartOptimization, OptimizationNLopt\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, MultistartOptimization.TikTak(100), NLopt.LD_LBFGS())","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"You can use any Optimization optimizers you like. The global method of the MultistartOptimization is a positional argument and followed by the local method. For example, we can perform a multistartoptimization with LBFGS as the optimizer using either the NLopt.jl or Optim.jl implementation as follows. Moreover, this interface allows you to access and adjust all the optimizer settings as you normally would:","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"using OptimizationOptimJL\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, MultistartOptimization.TikTak(100), LBFGS(), maxiters=5)","category":"page"},{"location":"API/optimization_function/#optfunction","page":"OptimizationFunction","title":"OptimizationFunction","text":"","category":"section"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"SciMLBase.OptimizationFunction","category":"page"},{"location":"API/optimization_function/#SciMLBase.OptimizationFunction","page":"OptimizationFunction","title":"SciMLBase.OptimizationFunction","text":"OptimizationFunction{iip,AD,F,G,H,HV,C,CJ,CH,HP,CJP,CHP,S,S2,HCV,CJCV,CHCV} <: AbstractOptimizationFunction{iip,specialize}\n\nA representation of an optimization of an objective function f, defined by:\n\nmin_u f(up)\n\nand all of its related functions, such as the gradient of f, its Hessian, and more. For all cases, u is the state and p are the parameters.\n\nConstructor\n\nOptimizationFunction{iip}(f, adtype::AbstractADType = NoAD();\n                          grad = nothing, hess = nothing, hv = nothing,\n                          cons = nothing, cons_j = nothing, cons_h = nothing,\n                          lag_h = nothing,\n                          hess_prototype = nothing, cons_jac_prototype = __has_jac_prototype(f) ? f.jac_prototype : nothing,\n                          cons_hess_prototype = nothing,\n                          lag_hess_prototype = nothing,\n                          syms = __has_syms(f) ? f.syms : nothing,\n                          paramsyms = __has_paramsyms(f) ? f.paramsyms : nothing,\n                          observed = __has_observed(f) ? f.observed : DEFAULT_OBSERVED_NO_TIME,\n                          hess_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\n                          cons_jac_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\n                          cons_hess_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\n                          lag_hess_colorvec = nothing,\n                          sys = __has_sys(f) ? f.sys : nothing)\n\nPositional Arguments\n\nf(u,p): the function to optimize. u are the state variables and p are the hyperparameters of the optimization. This function should return a scalar.\nadtype: see the section \"Defining Optimization Functions via AD\"\n\nKeyword Arguments\n\ngrad(G,u,p) or G=grad(u,p): the gradient of f with respect to u\nhess(H,u,p) or H=hess(u,p): the Hessian of f with respect to u\nhv(Hv,u,v,p) or Hv=hv(u,v,p): the Hessian-vector product (d^2 f  du^2) v.\ncons(res,x,p) or cons(x,p) : the constraints function, should mutate or return a vector   with value of the ith constraint, evaluated at the current values of variables   inside the optimization routine. This takes just the function evaluations   and the equality or inequality assertion is applied by the solver based on the constraint   bounds passed as lcons and ucons to OptimizationProblem, in case of equality   constraints lcons and ucons should be passed equal values.\ncons_j(res,x,p) or res=cons_j(x,p): the Jacobian of the constraints.\ncons_h(res,x,p) or res=cons_h(x,p): the Hessian of the constraints, provided as  an array of Hessians with res[i] being the Hessian with respect to the ith output on cons.\nlag_h(res,x,sigma,mu,p) or res=lag_h(x,sigma,mu,p): the Hessian of the Lagrangian,   where sigma is a multiplier of the cost function and mu are the lagrange multipliers   multiplying the constraints. This can be provided instead of hess and cons_h   to solvers that directly use the Hessian of the Lagrangian.\nparamjac(pJ,u,p): returns the parameter Jacobian dfdp.\nhess_prototype: a prototype matrix matching the type that matches the Hessian. For example, if the Hessian is tridiagonal, then an appropriately sized Hessian matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Hessian. The default is nothing, which means a dense Hessian.\ncons_jac_prototype: a prototype matrix matching the type that matches the constraint Jacobian. The default is nothing, which means a dense constraint Jacobian.\ncons_hess_prototype: a prototype matrix matching the type that matches the constraint Hessian. This is defined as an array of matrices, where hess[i] is the Hessian w.r.t. the ith output. For example, if the Hessian is sparse, then hess is a Vector{SparseMatrixCSC}. The default is nothing, which means a dense constraint Hessian.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nparamsyms: the symbol names for the parameters of the equation. This should match p in size. For example, if p = [0.0, 1.0] and paramsyms = [:a, :b], this will apply a canonical naming to the values, allowing sol[:a] in the solution.\nhess_colorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the hess_prototype. This specializes the Hessian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\ncons_jac_colorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the cons_jac_prototype.\ncons_hess_colorvec: an array of color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the cons_hess_prototype.\n\nDefining Optimization Functions Via AD\n\nWhile using the keyword arguments gives the user control over defining all of the possible functions, the simplest way to handle the generation of an OptimizationFunction is by specifying an AD type. By doing so, this will automatically fill in all of the extra functions. For example,\n\nOptimizationFunction(f,AutoZygote())\n\nwill use Zygote.jl to define all of the necessary functions. Note that if any functions are defined directly, the auto-AD definition does not overwrite the user's choice.\n\nEach of the AD-based constructors are documented separately via their own dispatches.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nspecialize: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the OptimizationFunction type directly match the names of the inputs.\n\n\n\n\n\n","category":"type"},{"location":"API/optimization_function/#Automatic-Differentiation-Construction-Choice-Recommendations","page":"OptimizationFunction","title":"Automatic Differentiation Construction Choice Recommendations","text":"","category":"section"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"The choices for the auto-AD fill-ins with quick descriptions are:","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"AutoForwardDiff(): The fastest choice for small optimizations\nAutoReverseDiff(compile=false): A fast choice for large scalar optimizations\nAutoTracker(): Like ReverseDiff but GPU-compatible\nAutoZygote(): The fastest choice for non-mutating array-based (BLAS) functions\nAutoFiniteDiff(): Finite differencing, not optimal but always applicable\nAutoModelingToolkit(): The fastest choice for large scalar optimizations","category":"page"},{"location":"API/optimization_function/#Automatic-Differentiation-Choice-API","page":"OptimizationFunction","title":"Automatic Differentiation Choice API","text":"","category":"section"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"The following sections describe the Auto-AD choices in detail.","category":"page"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"Optimization.AutoForwardDiff\nOptimization.AutoFiniteDiff\nOptimization.AutoReverseDiff\nOptimization.AutoZygote\nOptimization.AutoTracker\nOptimization.AutoModelingToolkit","category":"page"},{"location":"API/optimization_function/#Optimization.AutoForwardDiff","page":"OptimizationFunction","title":"Optimization.AutoForwardDiff","text":"AutoForwardDiff{chunksize} <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f,AutoForwardDiff();kwargs...)\n\nThis uses the ForwardDiff.jl package. It is the fastest choice for small systems, especially with heavy scalar interactions. It is easy to use and compatible with most Julia functions which have loose type restrictions. However, because it's forward-mode, it scales poorly in comparison to other AD choices. Hessian construction is suboptimal as it uses the forward-over-forward approach.\n\nCompatible with GPUs\nCompatible with Hessian-based optimization\nCompatible with Hv-based optimization\nCompatible with constraints\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not defined via ForwardDiff.\n\n\n\n\n\n","category":"type"},{"location":"API/optimization_function/#Optimization.AutoFiniteDiff","page":"OptimizationFunction","title":"Optimization.AutoFiniteDiff","text":"AutoFiniteDiff{T1,T2,T3} <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f,AutoFiniteDiff();kwargs...)\n\nThis uses FiniteDiff.jl. While not necessarily the most efficient, this is the only choice that doesn't require the f function to be automatically differentiable, which means it applies to any choice. However, because it's using finite differencing, one needs to be careful as this procedure introduces numerical error into the derivative estimates.\n\nCompatible with GPUs\nCompatible with Hessian-based optimization\nCompatible with Hv-based optimization\nCompatible with constraint functions\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not defined via FiniteDiff.\n\nConstructor\n\nAutoFiniteDiff(;fdtype = Val(:forward) fdjtype = fdtype, fdhtype = Val(:hcentral))\n\nfdtype: the method used for defining the gradient\nfdjtype: the method used for defining the Jacobian of constraints.\nfdhtype: the method used for defining the Hessian\n\nFor more information on the derivative type specifiers, see the FiniteDiff.jl documentation.\n\n\n\n\n\n","category":"type"},{"location":"API/optimization_function/#Optimization.AutoReverseDiff","page":"OptimizationFunction","title":"Optimization.AutoReverseDiff","text":"AutoReverseDiff <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f,AutoReverseDiff();kwargs...)\n\nThis uses the ReverseDiff.jl package. AutoReverseDiff has a default argument, compile, which denotes whether the reverse pass should be compiled. compile should only be set to true if f contains no branches (if statements, while loops) otherwise it can produce incorrect derivatives!\n\nAutoReverseDiff is generally applicable to many pure Julia codes, and with compile=true it is one of the fastest options on code with heavy scalar interactions. Hessian calculations are fast by mixing ForwardDiff with ReverseDiff for forward-over-reverse. However, its performance can falter when compile=false.\n\nNot compatible with GPUs\nCompatible with Hessian-based optimization by mixing with ForwardDiff\nCompatible with Hv-based optimization by mixing with ForwardDiff\nNot compatible with constraint functions\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not defined via ReverseDiff.\n\nConstructor\n\nAutoReverseDiff(;compile = false)\n\nNote: currently, compilation is not defined/used!\n\n\n\n\n\n","category":"type"},{"location":"API/optimization_function/#Optimization.AutoZygote","page":"OptimizationFunction","title":"Optimization.AutoZygote","text":"AutoZygote <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f,AutoZygote();kwargs...)\n\nThis uses the Zygote.jl package. This is the staple reverse-mode AD that handles a large portion of Julia with good efficiency. Hessian construction is fast via forward-over-reverse mixing ForwardDiff.jl with Zygote.jl\n\nCompatible with GPUs\nCompatible with Hessian-based optimization via ForwardDiff\nCompatible with Hv-based optimization via ForwardDiff\nNot compatible with constraint functions\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not defined via Zygote.\n\n\n\n\n\n","category":"type"},{"location":"API/optimization_function/#Optimization.AutoTracker","page":"OptimizationFunction","title":"Optimization.AutoTracker","text":"AutoTracker <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f,AutoTracker();kwargs...)\n\nThis uses the Tracker.jl package. Generally slower than ReverseDiff, it is generally applicable to many pure Julia codes.\n\nCompatible with GPUs\nNot compatible with Hessian-based optimization\nNot compatible with Hv-based optimization\nNot compatible with constraint functions\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not defined via Tracker.\n\n\n\n\n\n","category":"type"},{"location":"API/modelingtoolkit/#ModelingToolkit-Integration","page":"ModelingToolkit Integration","title":"ModelingToolkit Integration","text":"","category":"section"},{"location":"API/modelingtoolkit/","page":"ModelingToolkit Integration","title":"ModelingToolkit Integration","text":"Optimization.jl is heavily integrated with the ModelingToolkit.jl symbolic system for symbolic-numeric optimizations. It provides a front-end for automating the construction, parallelization, and optimization of code. Optimizers can better interface with the extra symbolic information provided by the system.","category":"page"},{"location":"API/modelingtoolkit/","page":"ModelingToolkit Integration","title":"ModelingToolkit Integration","text":"There are two ways that the user interacts with ModelingToolkit.jl. One can use OptimizationFunction with AutoModelingToolkit for automatically transforming numerical codes into symbolic codes. See the OptimizationFunction documentation for more details.","category":"page"},{"location":"API/modelingtoolkit/","page":"ModelingToolkit Integration","title":"ModelingToolkit Integration","text":"Secondly, one can generate OptimizationProblems for use in Optimization.jl from purely a symbolic front-end. This is the form users will encounter when using ModelingToolkit.jl directly, and it is also the form supplied by domain-specific languages. For more information, see the OptimizationSystem documentation.","category":"page"},{"location":"tutorials/symbolic/#Symbolic-Problem-Building-with-ModelingToolkit","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"","category":"section"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"note: Note\nThis example uses the OptimizationOptimJL.jl package. See the Optim.jl page for details on the installation and usage.","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"ModelingToolkit.jl is a comprehensive system for symbolic modeling in Julia. Allows for doing many manipulations before the solver phase, such as detecting sparsity patterns, analytically solving parts of the model to reduce the solving complexity, and more. One of the types of system types that it supports is OptimizationSystem, i.e., the symbolic counterpart to OptimizationProblem. Let's demonstrate how to use the OptimizationSystem to construct optimized OptimizationProblems.","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"First we need to start by defining our symbolic variables, this is done as follows:","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"using ModelingToolkit, Optimization, OptimizationOptimJL\r\n\r\n@variables x y\r\n@parameters a b","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"We can now construct the OptimizationSystem by building a symbolic expression  for the loss function:","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"loss = (a - x)^2 + b * (y - x^2)^2\r\n@named sys = OptimizationSystem(loss,[x,y],[a,b])","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"To turn it into a problem for numerical solutions, we need to specify what our parameter values are and the initial conditions. This looks like:","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"u0 = [\r\n    x=>1.0\r\n    y=>2.0\r\n]\r\np = [\r\n    a => 6.0\r\n    b => 7.0\r\n]","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"And now we solve.","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"prob = OptimizationProblem(sys,u0,p,grad=true,hess=true)\r\nsolve(prob,Newton())","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"It provides many other features like auto-parallelism and sparsification too. Plus, you can hierarchically nest systems to generate huge optimization problems. Check out the ModelingToolkit.jl OptimizationSystem documentation for more information.","category":"page"},{"location":"optimization_packages/gcmaes/#GCMAES.jl","page":"GCMAES.jl","title":"GCMAES.jl","text":"","category":"section"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"GCMAES is a Julia package implementing the Gradient-based Covariance Matrix Adaptation Evolutionary Strategy, which can utilize the gradient information to speed up the optimization process.","category":"page"},{"location":"optimization_packages/gcmaes/#Installation:-OptimizationGCMAES.jl","page":"GCMAES.jl","title":"Installation: OptimizationGCMAES.jl","text":"","category":"section"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"To use this package, install the OptimizationGCMAES package:","category":"page"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"import Pkg; Pkg.add(\"OptimizationGCMAES\")","category":"page"},{"location":"optimization_packages/gcmaes/#Global-Optimizer","page":"GCMAES.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/gcmaes/#Without-Constraint-Equations","page":"GCMAES.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"The GCMAES algorithm is called by GCMAESOpt() and the initial search variance is set as a keyword argument σ0 (default: σ0 = 0.2)","category":"page"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"The method in GCMAES is performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/gcmaes/#Example","page":"GCMAES.jl","title":"Example","text":"","category":"section"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"The Rosenbrock function can be optimized using the GCMAESOpt() without utilizing the gradient information as follows:","category":"page"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"using Optimization, OptimizationGCMAES\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, GCMAESOpt())","category":"page"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"We can also utilize the gradient information of the optimization problem to aid the optimization as follows:","category":"page"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"f = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, GCMAESOpt())","category":"page"},{"location":"optimization_packages/optimisers/#optimisers","page":"Optimisers.jl","title":"Optimisers.jl","text":"","category":"section"},{"location":"optimization_packages/optimisers/#Installation:-OptimizationFlux.jl","page":"Optimisers.jl","title":"Installation: OptimizationFlux.jl","text":"","category":"section"},{"location":"optimization_packages/optimisers/","page":"Optimisers.jl","title":"Optimisers.jl","text":"To use this package, install the OptimizationOptimisers package:","category":"page"},{"location":"optimization_packages/optimisers/","page":"Optimisers.jl","title":"Optimisers.jl","text":"import Pkg; Pkg.add(\"OptimizationOptimisers\")","category":"page"},{"location":"optimization_packages/optimisers/#Local-Unconstrained-Optimizers","page":"Optimisers.jl","title":"Local Unconstrained Optimizers","text":"","category":"section"},{"location":"optimization_packages/optimisers/","page":"Optimisers.jl","title":"Optimisers.jl","text":"Optimisers.Descent: Classic gradient descent optimizer with learning rate\nsolve(problem, Descent(η))\nη is the learning rate\nDefaults:\nη = 0.1\nOptimisers.Momentum: Classic gradient descent optimizer with learning rate and momentum\nsolve(problem, Momentum(η, ρ))\nη is the learning rate\nρ is the momentum\nDefaults:\nη = 0.01\nρ = 0.9\nOptimisers.Nesterov: Gradient descent optimizer with learning rate and Nesterov momentum\nsolve(problem, Nesterov(η, ρ))\nη is the learning rate\nρ is the Nesterov momentum\nDefaults:\nη = 0.01\nρ = 0.9\nOptimisers.RMSProp: RMSProp optimizer\nsolve(problem, RMSProp(η, ρ))\nη is the learning rate\nρ is the momentum\nDefaults:\nη = 0.001\nρ = 0.9\nOptimisers.Adam: Adam optimizer\nsolve(problem, Adam(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nOptimisers.RAdam: Rectified Adam optimizer\nsolve(problem, RAdam(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nOptimisers.RAdam: Optimistic Adam optimizer\nsolve(problem, OAdam(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.5, 0.999)\nOptimisers.AdaMax: AdaMax optimizer\nsolve(problem, AdaMax(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nOptimisers.ADAGrad: ADAGrad optimizer\nsolve(problem, ADAGrad(η))\nη is the learning rate\nDefaults:\nη = 0.1\nOptimisers.ADADelta: ADADelta optimizer\nsolve(problem, ADADelta(ρ))\nρ is the gradient decay factor\nDefaults:\nρ = 0.9\nOptimisers.AMSGrad: AMSGrad optimizer\nsolve(problem, AMSGrad(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nOptimisers.NAdam: Nesterov variant of the Adam optimizer\nsolve(problem, NAdam(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nOptimisers.AdamW: AdamW optimizer\nsolve(problem, AdamW(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\ndecay is the decay to weights\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\ndecay = 0\nOptimisers.ADABelief: ADABelief variant of Adam\nsolve(problem, ADABelief(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)","category":"page"},{"location":"API/FAQ/#Frequently-Asked-Questions","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"","category":"section"},{"location":"API/FAQ/#The-Solver-Seems-to-Violate-Constraints-During-the-Optimization,-Causing-DomainErrors,-What-Can-I-Do-About-That?","page":"Frequently Asked Questions","title":"The Solver Seems to Violate Constraints During the Optimization, Causing DomainErrors, What Can I Do About That?","text":"","category":"section"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"During the optimization, optimizers use slack variables to relax the solution to the constraints. Because of this, there is no guarantee that for an arbitrary optimizer the steps will all satisfy the constraints during the  optimization. In many cases, this can cause one's objective function code throw a DomainError if it is evaluated outside of its acceptable zone. For example, log(-1) gives:","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"julia> log(-1)\nERROR: DomainError with -1.0:\nlog will only return a complex result if called with a complex argument. Try log(Complex(x)).","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"To handle this, one should not assume that the variables will always satisfy the constraints on each step. There are three general ways to handle this better:","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"Use NaNMath.jl\nProcess variables before domain-restricted calls\nUse a domain transformation","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"NaNMath.jl gives alternative implementations of standard math functions like log and sqrt in forms that do not throw DomainErrors but rather return NaNs. The optimizers will be able to handle the NaNs gracefully and recover, allowing for many of these cases to be solved without further modification. Note that this is done internally in JuMP.jl, and thus if a case is working with JuMP and not Optimization.jl  this may be the  reason for the difference.","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"Alternatively, one can pre-process the values directly. For example, log(abs(x)) is guaranteed to work. If one does this, there are two things to make note of. One is that the solution will not be transformed, and thus the transformation should be applied on sol.u as well. For example, the solution could find an optima for x = -2, and one should manually change this to x = 2 if the abs version is used within the objective function. Note that many functions for this will introduce a discontinuity in the derivative which can affect the optimization process.","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"Finally and relatedly, one can write the optimization with domain transformations in order to allow the optimization to take place in the full real set. For example, instead of optimizing x in [0,Inf], one can optimize exp(x) in [0,Inf] and thus x in [-Inf, Inf] is allowed without any bounds. To do this, you would simply add the transformations to the top of the objective function:","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"function my_objective(u)\n    x = exp(u[1])\n    # ... use x\nend","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"When the optimization is done, sol.u[1] will be exp(x) and thus log(sol.u[1]) will be the optimal value for x. There exist packages in the Julia ecosystem which make it easier to keep track of these domain transformations and their inverses for more general domains. See TransformVariables.jl and Bijectors.jl for high level interfaces for this.","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"While this can allow an optimization with constraints to be rewritten as one without constraints, note that this can change the numerical properties of the solve which can either improve or decrease the numerical stability in a case-by-case basis. Thus while a solution, one should be aware that it could make the optimization more difficult in some cases.","category":"page"},{"location":"API/FAQ/#What-are-the-advantages-and-disadvantages-of-using-the-ModelingToolkit.jl-or-other-symbolic-interfaces-(JuMP)?","page":"Frequently Asked Questions","title":"What are the advantages and disadvantages of using the ModelingToolkit.jl or other symbolic interfaces (JuMP)?","text":"","category":"section"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"The purely numerical function interfaces of Optimization.jl has its pros and cons. The major pro of the direct Optimization.jl interface is that it can take arbitrary Julia programs. If you have an optimization defined over a program, like a Neural ODE or something that calls out to web servers, then these advanced setups rarely work within specialized symbolic environments for optimization. Direct usage of Optimization.jl is thus the preferred route for this kind of problem, and is the popular choice in the Julia ecosystem for these cases due to the simplicity of use.","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"However, symbolic interfaces are smart, and they may know more than you for how to make this optimization faster. And symbolic interfaces are willing to do \"tedious work\" in order to make the optimization more efficient. For example, the ModelingToolkit integration with Optimization.jl will do many simplifications when structural_simplify is called. One of them is tearing on the constraints. To understand the tearing process, assume that we had nonlinear constraints of the form:","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"    0 ~ u1 - sin(u5) * h,\n    0 ~ u2 - cos(u1),\n    0 ~ u3 - hypot(u1, u2),\n    0 ~ u4 - hypot(u2, u3),","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"If these were the constraints, one can write u1 = sin(u5) * h and substitute u1 for this value in the objective function. If this is done, then u1 does not need to be solved for, the optimization has one less state variable and one less constraint. One can continue this process all the way to a bunch of functions:","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"u1 = f1(u5)\nu2 = f2(u1)\nu3 = f3(u1, u2)\nu4 = f4(u2, u3)","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"and thus if the objective function was the function of these 5 variables and 4 constraints, ModelingToolkit.jl will  transform it into system of 1 variable with no constraints, allowing unconstrained optimization on a smaller system. This will both be faster and numerically easier.","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"JuMP.jl is another symbolic interface. While it does not include these tearing and symbolic simplification passes, it does include the ability to specialize the solution process. For example, it can treat linear optimization problems, quadratic optimization problem, convex optimization problems, etc. in specific ways that are more efficient than a general nonlinear interface. For more information on the types of special solves that are allowed with JuMP, see this page.","category":"page"},{"location":"optimization_packages/evolutionary/#Evolutionary.jl","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"","category":"section"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"Evolutionary is a Julia package implementing various evolutionary and genetic algorithm.","category":"page"},{"location":"optimization_packages/evolutionary/#Installation:-OptimizationEvolutionary.jl","page":"Evolutionary.jl","title":"Installation: OptimizationEvolutionary.jl","text":"","category":"section"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"To use this package, install the OptimizationEvolutionary package:","category":"page"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"import Pkg; Pkg.add(\"OptimizationEvolutionary\")","category":"page"},{"location":"optimization_packages/evolutionary/#Global-Optimizer","page":"Evolutionary.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/evolutionary/#Without-Constraint-Equations","page":"Evolutionary.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"The methods in Evolutionary are performing global optimization on problems without constraint equations. These methods work both with and without lower and upper constraints set by lb and ub in the OptimizationProblem.","category":"page"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"A Evolutionary algorithm is called by one of the following:","category":"page"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"Evolutionary.GA(): Genetic Algorithm optimizer\nEvolutionary.DE(): Differential Evolution optimizer\nEvolutionary.ES(): Evolution Strategy algorithm\nEvolutionary.CMAES(): Covariance Matrix Adaptation Evolution Strategy algorithm","category":"page"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"Algorithm-specific options are defined as kwargs. See the respective documentation for more detail.","category":"page"},{"location":"optimization_packages/evolutionary/#Example","page":"Evolutionary.jl","title":"Example","text":"","category":"section"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"The Rosenbrock function can be optimized using the Evolutionary.CMAES() as follows:","category":"page"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"using Optimization, OptimizationEvolutionary\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, Evolutionary.CMAES(μ =40 , λ = 100))","category":"page"},{"location":"optimization_packages/quaddirect/#QuadDIRECT.jl","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"","category":"section"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"QuadDIRECT is a Julia package implementing QuadDIRECT algorithm (inspired by DIRECT and MCS). ","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"The QuadDIRECT algorithm is called using QuadDirect(). ","category":"page"},{"location":"optimization_packages/quaddirect/#Installation:-OptimizationQuadDIRECT.jl","page":"QuadDIRECT.jl","title":"Installation: OptimizationQuadDIRECT.jl","text":"","category":"section"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"To use this package, install the OptimizationQuadDIRECT package as:","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"import Pkg; Pkg.add(url=\"https://github.com/SciML/Optimization.jl\", subdir = \"lib/OptimizationQuadDIRECT\")","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"Also note that QuadDIRECT should (for now) be installed by doing:","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"] add https://github.com/timholy/QuadDIRECT.jl.git","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"Since QuadDIRECT is not a registered package in General registry, OptimizationQuadDIRECT is not registered as well, and hence it can't be installed with the traditional command.","category":"page"},{"location":"optimization_packages/quaddirect/#Global-Optimizer","page":"QuadDIRECT.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/quaddirect/#Without-Constraint-Equations","page":"QuadDIRECT.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"The algorithm in QuadDIRECT is performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"Furthermore, QuadDirect requires splits which is a list of 3-vectors with initial locations at which to evaluate the function (the values must be in strictly increasing order and lie within the specified bounds) such that solve(problem, QuadDirect(), splits).","category":"page"},{"location":"optimization_packages/quaddirect/#Example","page":"QuadDIRECT.jl","title":"Example","text":"","category":"section"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"The Rosenbrock function can be optimized using the QuadDirect() as follows:","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsolve(prob, QuadDirect(), splits = ([-0.9, 0, 0.9], [-0.8, 0, 0.8]))","category":"page"},{"location":"tutorials/intro/#Basic-usage","page":"Basic usage","title":"Basic usage","text":"","category":"section"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"In this tutorial, we introduce the basics of Optimization.jl by showing how to easily mix local optimizers from Optim.jl and global optimizers from BlackBoxOptim.jl on the Rosenbrock equation. The simplest copy-pasteable code to get started is the following:","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"# Import the package and define the problem to optimize\nusing Optimization\nrosenbrock(u,p) =  (p[1] - u[1])^2 + p[2] * (u[2] - u[1]^2)^2\nu0 = zeros(2)\np  = [1.0,100.0]\n\nprob = OptimizationProblem(rosenbrock,u0,p)\n\n# Import a solver package and solve the optimization problem\nusing OptimizationOptimJL\nsol = solve(prob,NelderMead())\n\n# Import a different solver package and solve the optimization problem a different way\nusing OptimizationBBO\nprob = OptimizationProblem(rosenbrock, u0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob,BBO_adaptive_de_rand_1_bin_radiuslimited())","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"Notice that Optimization.jl is the core glue package that holds all the common pieces, but to solve the equations, we need to use a solver package. Here, OptimizationOptimJL is for Optim.jl and OptimizationBBO is for BlackBoxOptim.jl.","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"The output of the first optimization task (with the NelderMead() algorithm) is given below:","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"optf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = OptimizationProblem(optf, u0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob,NelderMead())","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"The solution from the original solver can always be obtained via original:","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"sol.original","category":"page"},{"location":"tutorials/intro/#Controlling-Gradient-Calculations-(Automatic-Differentiation)","page":"Basic usage","title":"Controlling Gradient Calculations (Automatic Differentiation)","text":"","category":"section"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"Notice that both of the above methods were derivative-free methods, and thus no gradients were required to do the optimization. However, often first order optimization (i.e., using gradients) is much more efficient. Defining gradients can be done in two ways. One way is to manually provide a gradient definition in the OptimizationFunction constructor. However, the more convenient way to obtain gradients is to provide an AD backend type. ","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"For example, let's now use the OptimizationOptimJL BFGS method to solve the same problem. We will import the forward-mode automatic differentiation library (using ForwardDiff) and then specify in the OptimizationFunction to automatically construct the derivative functions using ForwardDiff.jl. This looks like:","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"using ForwardDiff\noptf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = OptimizationProblem(optf, u0, p)\nsol = solve(prob,BFGS())","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"We can inspect the original to see the statistics on the number of steps  required and gradients computed:","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"sol.original","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"Sure enough, it's a lot less than the derivative-free methods!","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"However, the compute cost of forward-mode automatic differentiation scales via the number of inputs, and thus as our optimization problem grows large it slows down. To counteract this, for larger optimization problems (>100 state variables) one normally would want to use reverse-mode automatic differentiation. One common choice for reverse-mode automatic differentiation is Zygote.jl. We can demonstrate this via:","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"using Zygote\noptf = OptimizationFunction(rosenbrock, Optimization.AutoZygote())\nprob = OptimizationProblem(optf, u0, p)\nsol = solve(prob,BFGS())","category":"page"},{"location":"tutorials/intro/#Setting-Box-Constraints","page":"Basic usage","title":"Setting Box Constraints","text":"","category":"section"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"In many cases, one knows the potential bounds on the solution values. In Optimization.jl, these can be supplied as the lb and ub arguments for the lower bounds and upper bounds respectively, supplying a vector of values with one per state variable. Let's now do our gradient-based optimization with box constraints by rebuilding the OptimizationProblem:","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"prob = OptimizationProblem(optf, u0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob,BFGS())","category":"page"},{"location":"tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"For more information on handling constraints, in particular equality and inequality constraints, take a look at the constraints tutorial.","category":"page"},{"location":"#Optimization.jl:-A-Unified-Optimization-Package","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"","category":"section"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"Optimization.jl is a package with a scope that is beyond your normal global optimization package. Optimization.jl seeks to bring together all the optimization packages it can find, local and global, into one unified Julia interface. This means, you learn one package, and you learn them all! Optimization.jl adds a few high-level features, such as integrating with automatic differentiation, to make its usage fairly simple for most cases, while allowing all the options in a single unified interface.","category":"page"},{"location":"#Installation","page":"Optimization.jl: A Unified Optimization Package","title":"Installation","text":"","category":"section"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"Assuming that you already have Julia correctly installed, it suffices to import Optimization.jl in the standard way:","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"import Pkg\nPkg.add(\"Optimization\")","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"The packages relevant to the core functionality of Optimization.jl will be imported accordingly and, in most cases, you do not have to worry about the manual installation of dependencies. However, you will need to add the specific optimizer packages.","category":"page"},{"location":"#Contributing","page":"Optimization.jl: A Unified Optimization Package","title":"Contributing","text":"","category":"section"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to SciML.\nSee the SciML Style Guide for common coding practices and other style decisions.\nThere are a few community forums:\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Slack\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Zulip\nOn the Julia Discourse forums\nSee also SciML Community page","category":"page"},{"location":"#Overview-of-the-Optimizers","page":"Optimization.jl: A Unified Optimization Package","title":"Overview of the Optimizers","text":"","category":"section"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"Package Local Gradient-Based Local Hessian-Based Local Derivative-Free Local Constrained Global Unconstrained Global Constrained\nBlackBoxOptim ❌ ❌ ❌ ❌ ✅ ❌\nCMAEvolutionaryStrategy ❌ ❌ ❌ ❌ ✅ ❌\nEvolutionary ❌ ❌ ❌ ❌ ✅ 🟡\nFlux ✅ ❌ ❌ ❌ ❌ ❌\nGCMAES ❌ ❌ ❌ ❌ ✅ ❌\nMathOptInterface ✅ ✅ ✅ ✅ ✅ 🟡\nMultistartOptimization ❌ ❌ ❌ ❌ ✅ ❌\nMetaheuristics ❌ ❌ ❌ ❌ ✅ 🟡\nNOMAD ❌ ❌ ❌ ❌ ✅ 🟡\nNLopt ✅ ❌ ✅ 🟡 ✅ 🟡\nNonconvex ✅ ✅ ✅ 🟡 ✅ 🟡\nOptim ✅ ✅ ✅ ✅ ✅ ✅\nQuadDIRECT ❌ ❌ ❌ ❌ ✅ ❌","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"✅ = supported","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"🟡 = supported in downstream library but not yet implemented in Optimization; PR to add this functionality are welcome","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"❌ = not supported","category":"page"},{"location":"#Reproducibility","page":"Optimization.jl: A Unified Optimization Package","title":"Reproducibility","text":"","category":"section"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"<details><summary>The documentation of this SciML package was built using these direct dependencies,</summary>","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"using Pkg # hide\nPkg.status() # hide","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"</details>","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"<details><summary>and using this machine and Julia version.</summary>","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"using InteractiveUtils # hide\nversioninfo() # hide","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"</details>","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"using Pkg # hide\nPkg.status(;mode = PKGMODE_MANIFEST) # hide","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"</details>","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"You can also download the \n<a href=\"","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"using TOML\nversion = TOML.parse(read(\"../../Project.toml\",String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\",String))[\"name\"]\nlink = \"https://github.com/SciML/\"*name*\".jl/tree/gh-pages/v\"*version*\"/assets/Manifest.toml\"","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"\">manifest</a> file and the\n<a href=\"","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"using TOML\nversion = TOML.parse(read(\"../../Project.toml\",String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\",String))[\"name\"]\nlink = \"https://github.com/SciML/\"*name*\".jl/tree/gh-pages/v\"*version*\"/assets/Project.toml\"","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"\">project</a> file.","category":"page"},{"location":"tutorials/constraints/#constraints","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"","category":"section"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"Multiple optimization packages available with the MathOptInterface and Optim's IPNewton solver can handle non-linear constraints. Optimization.jl provides a simple interface to define the constraint as a Julia function and then specify the bounds for the output in OptimizationFunction to indicate if it's an equality or inequality constraint.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"Let's define the rosenbrock function as our objective function and consider the below inequalities as our constraints.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"beginaligned\n\nx_1^2 + x_2^2 leq 08 \n\n00 leq x_1 * x_2 leq 50\nendaligned","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"using Optimization, OptimizationMOI, OptimizationOptimJL, Ipopt\nusing ForwardDiff, ModelingToolkit\n\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p = [1.0, 1.0]","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"Next, we define the sum of squares and the product of the optimization variables as our constraint functions.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"cons(res, x, p) = (res .= [x[1]^2+x[2]^2, x[1]*x[2]])","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"We'll use the IPNewton solver from Optim to solve the problem.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"optprob = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff(), cons = cons)\nprob = OptimizationProblem(optprob, x0, _p, lcons = [-Inf, -1.0], ucons = [0.8, 2.0])\nsol = solve(prob, IPNewton())","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"Let's check that the constraints are satisfied, and that the objective is lower than at initial values.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"res = zeros(2)\ncons(res, sol.u, _p)\nres","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"prob.f(sol.u, _p)","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"We can also use the Ipopt library with the OptimizationMOI package.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"sol = solve(prob, Ipopt.Optimizer())","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"res = zeros(2)\ncons(res, sol.u, _p)\nres","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"prob.f(sol.u, _p)","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"We can also use ModelingToolkit as our AD backend and generate symbolic derivatives and expression graph for the objective and constraints.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"Let's modify the bounds to use the function as an equality constraint. The constraint now becomes -","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"beginaligned\n\nx_1^2 + x_2^2 = 10 \n\nx_1 * x_2 = 05\nendaligned","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"optprob = OptimizationFunction(rosenbrock, Optimization.AutoModelingToolkit(), cons = cons)\nprob = OptimizationProblem(optprob, x0, _p, lcons = [1.0, 0.5], ucons = [1.0, 0.5])","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"Below, the AmplNLWriter.jl package is used with to use the Ipopt library to solve the problem.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"using AmplNLWriter, Ipopt_jll\nsol = solve(prob, AmplNLWriter.Optimizer(Ipopt_jll.amplexe))","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"The constraints evaluate to 1.0 and 0.5 respectively, as expected.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"res = zeros(2)\ncons(res, sol.u, _p)\nprintln(res)","category":"page"}]
}
